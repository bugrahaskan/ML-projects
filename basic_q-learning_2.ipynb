{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04f6d812-e859-4ee9-94bd-eb3c926ba891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearningAgent_mine:\n",
    "    def __init__(self, data, states, actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.data = data\n",
    "        \n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.pseudo_actions = []\n",
    "        \n",
    "        self.num_states = len(states)\n",
    "        self.num_actions = len(actions)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = np.zeros((self.num_states, self.num_actions))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            return self.actions[np.argmax(self.Q[self.states.index(state)])]\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        self.Q[self.states.index(state), self.actions.index(action)] += self.alpha * (\n",
    "                reward + self.gamma * np.max(self.Q[self.states.index(next_state)]) -\n",
    "                self.Q[self.states.index(state), self.actions.index(action)])\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        for episode in range(num_episodes):\n",
    "            state = np.random.choice(self.states)\n",
    "            #print(state)\n",
    "\n",
    "            if state == 'long':\n",
    "                self.pseudo_actions = ['sell', 'hold']\n",
    "            elif state == 'short':\n",
    "                self.pseudo_actions = ['buy', 'hold']\n",
    "\n",
    "            i = 0\n",
    "            total_reward = 0\n",
    "\n",
    "            while True:\n",
    "                price_open = self.data['close'].iloc[i] # position open price\n",
    "\n",
    "                for j in range(i+1, len(self.data['close'])):\n",
    "                    action = None\n",
    "                    while not action in self.pseudo_actions:\n",
    "                        action = self.choose_action(state)\n",
    "\n",
    "                    #print(action)\n",
    "\n",
    "                    if action == 'hold':\n",
    "                        price_close = self.data['close'].iloc[j]\n",
    "                        reward = self.get_reward(state, action, price_open, price_close)  # Define your reward function\n",
    "                        \n",
    "                        self.update_q_table(state, action, reward, state)\n",
    "                        \n",
    "                        continue\n",
    "                    else:\n",
    "                        price_close = self.data['close'].iloc[j]\n",
    "\n",
    "                        # Simulate environment and get reward and next state\n",
    "                        # Update state based on your financial data\n",
    "                        reward = self.get_reward(state, action, price_open, price_close)  # Define your reward function\n",
    "                        \n",
    "                        if reward >= 0:\n",
    "                            next_state = state\n",
    "                        elif reward < 0:\n",
    "                            next_idx = 1 if self.states.index(state) == 0 else 0\n",
    "                            next_state = self.states[next_idx]\n",
    "                            \n",
    "                        self.update_q_table(state, action, reward, next_state)\n",
    "                        state = next_state\n",
    "                i += 1\n",
    "\n",
    "                total_reward += reward\n",
    "                \n",
    "                # Check for terminal state\n",
    "                if i == len(self.data['close'])-1:\n",
    "                    break\n",
    "\n",
    "            print(\"Episode {}: Total Reward = {}\".format(episode + 1, total_reward))\n",
    "\n",
    "    def get_reward(self, state, action, price_open, price_close):\n",
    "\n",
    "        if state == 'long' and action == 'sell':\n",
    "            return 2 if price_close > price_open else -2\n",
    "        elif state == 'short' and action == 'buy':\n",
    "            return 2 if price_close < price_open else -2\n",
    "        elif state == 'long' and action == 'hold':\n",
    "            return 1 if price_close > price_open else -1\n",
    "        elif state == 'short' and action == 'hold':\n",
    "            return 1 if price_close < price_open else -1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da5839ec-a5c7-40b4-b85f-06a61d03711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_sample.csv')\n",
    "data = data.iloc[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64261cf2-5cf5-4d99-926e-28f2513128c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 447\n",
      "Episode 2: Total Reward = -209\n",
      "Episode 3: Total Reward = 447\n",
      "Episode 4: Total Reward = -243\n",
      "Episode 5: Total Reward = -217\n",
      "Episode 6: Total Reward = -218\n",
      "Episode 7: Total Reward = -224\n",
      "Episode 8: Total Reward = -254\n",
      "Episode 9: Total Reward = -232\n",
      "Episode 10: Total Reward = 439\n",
      "Episode 11: Total Reward = 445\n",
      "Episode 12: Total Reward = 446\n",
      "Episode 13: Total Reward = 456\n",
      "Episode 14: Total Reward = 453\n",
      "Episode 15: Total Reward = -226\n",
      "Episode 16: Total Reward = 448\n",
      "Episode 17: Total Reward = 442\n",
      "Episode 18: Total Reward = -246\n",
      "Episode 19: Total Reward = -257\n",
      "Episode 20: Total Reward = -253\n",
      "Episode 21: Total Reward = 483\n",
      "Episode 22: Total Reward = -231\n",
      "Episode 23: Total Reward = 479\n",
      "Episode 24: Total Reward = -255\n",
      "Episode 25: Total Reward = 479\n",
      "Episode 26: Total Reward = 476\n",
      "Episode 27: Total Reward = -254\n",
      "Episode 28: Total Reward = -257\n",
      "Episode 29: Total Reward = 481\n",
      "Episode 30: Total Reward = 482\n",
      "Episode 31: Total Reward = -243\n",
      "Episode 32: Total Reward = 483\n",
      "Episode 33: Total Reward = -256\n",
      "Episode 34: Total Reward = -275\n",
      "Episode 35: Total Reward = -254\n",
      "Episode 36: Total Reward = -257\n",
      "Episode 37: Total Reward = -251\n",
      "Episode 38: Total Reward = -233\n",
      "Episode 39: Total Reward = -257\n",
      "Episode 40: Total Reward = 477\n",
      "Episode 41: Total Reward = 481\n",
      "Episode 42: Total Reward = -268\n",
      "Episode 43: Total Reward = -264\n",
      "Episode 44: Total Reward = 477\n",
      "Episode 45: Total Reward = 477\n",
      "Episode 46: Total Reward = 477\n",
      "Episode 47: Total Reward = 475\n",
      "Episode 48: Total Reward = 468\n",
      "Episode 49: Total Reward = 478\n",
      "Episode 50: Total Reward = -255\n",
      "Episode 51: Total Reward = 480\n",
      "Episode 52: Total Reward = -248\n",
      "Episode 53: Total Reward = -241\n",
      "Episode 54: Total Reward = -237\n",
      "Episode 55: Total Reward = 475\n",
      "Episode 56: Total Reward = -253\n",
      "Episode 57: Total Reward = 476\n",
      "Episode 58: Total Reward = -259\n",
      "Episode 59: Total Reward = -257\n",
      "Episode 60: Total Reward = 469\n",
      "Episode 61: Total Reward = -256\n",
      "Episode 62: Total Reward = -252\n",
      "Episode 63: Total Reward = -280\n",
      "Episode 64: Total Reward = 472\n",
      "Episode 65: Total Reward = -240\n",
      "Episode 66: Total Reward = -231\n",
      "Episode 67: Total Reward = -258\n",
      "Episode 68: Total Reward = 480\n",
      "Episode 69: Total Reward = -244\n",
      "Episode 70: Total Reward = 482\n",
      "Episode 71: Total Reward = 478\n",
      "Episode 72: Total Reward = -241\n",
      "Episode 73: Total Reward = 468\n",
      "Episode 74: Total Reward = 475\n",
      "Episode 75: Total Reward = -238\n",
      "Episode 76: Total Reward = -269\n",
      "Episode 77: Total Reward = 478\n",
      "Episode 78: Total Reward = -264\n",
      "Episode 79: Total Reward = -251\n",
      "Episode 80: Total Reward = 474\n",
      "Episode 81: Total Reward = -261\n",
      "Episode 82: Total Reward = -232\n",
      "Episode 83: Total Reward = 474\n",
      "Episode 84: Total Reward = 473\n",
      "Episode 85: Total Reward = -260\n",
      "Episode 86: Total Reward = -234\n",
      "Episode 87: Total Reward = 473\n",
      "Episode 88: Total Reward = -258\n",
      "Episode 89: Total Reward = -260\n",
      "Episode 90: Total Reward = 470\n",
      "Episode 91: Total Reward = -234\n",
      "Episode 92: Total Reward = 474\n",
      "Episode 93: Total Reward = 475\n",
      "Episode 94: Total Reward = 477\n",
      "Episode 95: Total Reward = 476\n",
      "Episode 96: Total Reward = 473\n",
      "Episode 97: Total Reward = -241\n",
      "Episode 98: Total Reward = -236\n",
      "Episode 99: Total Reward = -254\n",
      "Episode 100: Total Reward = -244\n",
      "Episode 101: Total Reward = 475\n",
      "Episode 102: Total Reward = 479\n",
      "Episode 103: Total Reward = -245\n",
      "Episode 104: Total Reward = -252\n",
      "Episode 105: Total Reward = -257\n",
      "Episode 106: Total Reward = -252\n",
      "Episode 107: Total Reward = -239\n",
      "Episode 108: Total Reward = -255\n",
      "Episode 109: Total Reward = 472\n",
      "Episode 110: Total Reward = -254\n",
      "Episode 111: Total Reward = -254\n",
      "Episode 112: Total Reward = 476\n",
      "Episode 113: Total Reward = -232\n",
      "Episode 114: Total Reward = -239\n",
      "Episode 115: Total Reward = -240\n",
      "Episode 116: Total Reward = -258\n",
      "Episode 117: Total Reward = 479\n",
      "Episode 118: Total Reward = 476\n",
      "Episode 119: Total Reward = 477\n",
      "Episode 120: Total Reward = -254\n",
      "Episode 121: Total Reward = -259\n",
      "Episode 122: Total Reward = -270\n",
      "Episode 123: Total Reward = -239\n",
      "Episode 124: Total Reward = -251\n",
      "Episode 125: Total Reward = -243\n",
      "Episode 126: Total Reward = 472\n",
      "Episode 127: Total Reward = -256\n",
      "Episode 128: Total Reward = -228\n",
      "Episode 129: Total Reward = -243\n",
      "Episode 130: Total Reward = 470\n",
      "Episode 131: Total Reward = 473\n",
      "Episode 132: Total Reward = 466\n",
      "Episode 133: Total Reward = 483\n",
      "Episode 134: Total Reward = 473\n",
      "Episode 135: Total Reward = 476\n",
      "Episode 136: Total Reward = 470\n",
      "Episode 137: Total Reward = 478\n",
      "Episode 138: Total Reward = 480\n",
      "Episode 139: Total Reward = -267\n",
      "Episode 140: Total Reward = 475\n",
      "Episode 141: Total Reward = -255\n",
      "Episode 142: Total Reward = 472\n",
      "Episode 143: Total Reward = -262\n",
      "Episode 144: Total Reward = 477\n",
      "Episode 145: Total Reward = 477\n",
      "Episode 146: Total Reward = 474\n",
      "Episode 147: Total Reward = -242\n",
      "Episode 148: Total Reward = 479\n",
      "Episode 149: Total Reward = -232\n",
      "Episode 150: Total Reward = -245\n",
      "Episode 151: Total Reward = -240\n",
      "Episode 152: Total Reward = -248\n",
      "Episode 153: Total Reward = 472\n",
      "Episode 154: Total Reward = -262\n",
      "Episode 155: Total Reward = 480\n",
      "Episode 156: Total Reward = 479\n",
      "Episode 157: Total Reward = 476\n",
      "Episode 158: Total Reward = 471\n",
      "Episode 159: Total Reward = -250\n",
      "Episode 160: Total Reward = -239\n",
      "Episode 161: Total Reward = -249\n",
      "Episode 162: Total Reward = -256\n",
      "Episode 163: Total Reward = -263\n",
      "Episode 164: Total Reward = -229\n",
      "Episode 165: Total Reward = -247\n",
      "Episode 166: Total Reward = -251\n",
      "Episode 167: Total Reward = -239\n",
      "Episode 168: Total Reward = 477\n",
      "Episode 169: Total Reward = -251\n",
      "Episode 170: Total Reward = -238\n",
      "Episode 171: Total Reward = -254\n",
      "Episode 172: Total Reward = 473\n",
      "Episode 173: Total Reward = -249\n",
      "Episode 174: Total Reward = -243\n",
      "Episode 175: Total Reward = 478\n",
      "Episode 176: Total Reward = -276\n",
      "Episode 177: Total Reward = -267\n",
      "Episode 178: Total Reward = 473\n",
      "Episode 179: Total Reward = -260\n",
      "Episode 180: Total Reward = 477\n",
      "Episode 181: Total Reward = 474\n",
      "Episode 182: Total Reward = 477\n",
      "Episode 183: Total Reward = 471\n",
      "Episode 184: Total Reward = -230\n",
      "Episode 185: Total Reward = -240\n",
      "Episode 186: Total Reward = 475\n",
      "Episode 187: Total Reward = 477\n",
      "Episode 188: Total Reward = 473\n",
      "Episode 189: Total Reward = -233\n",
      "Episode 190: Total Reward = -260\n",
      "Episode 191: Total Reward = 466\n",
      "Episode 192: Total Reward = -235\n",
      "Episode 193: Total Reward = 478\n",
      "Episode 194: Total Reward = 476\n",
      "Episode 195: Total Reward = 479\n",
      "Episode 196: Total Reward = 469\n",
      "Episode 197: Total Reward = 468\n",
      "Episode 198: Total Reward = -245\n",
      "Episode 199: Total Reward = 480\n",
      "Episode 200: Total Reward = 478\n",
      "Episode 201: Total Reward = 476\n",
      "Episode 202: Total Reward = 477\n",
      "Episode 203: Total Reward = -243\n",
      "Episode 204: Total Reward = 468\n",
      "Episode 205: Total Reward = 473\n",
      "Episode 206: Total Reward = -247\n",
      "Episode 207: Total Reward = 465\n",
      "Episode 208: Total Reward = -264\n",
      "Episode 209: Total Reward = 476\n",
      "Episode 210: Total Reward = 479\n",
      "Episode 211: Total Reward = 475\n",
      "Episode 212: Total Reward = -253\n",
      "Episode 213: Total Reward = 475\n",
      "Episode 214: Total Reward = -237\n",
      "Episode 215: Total Reward = -236\n",
      "Episode 216: Total Reward = -252\n",
      "Episode 217: Total Reward = 476\n",
      "Episode 218: Total Reward = 474\n",
      "Episode 219: Total Reward = -260\n",
      "Episode 220: Total Reward = -253\n",
      "Episode 221: Total Reward = -242\n",
      "Episode 222: Total Reward = 465\n",
      "Episode 223: Total Reward = 476\n",
      "Episode 224: Total Reward = 472\n",
      "Episode 225: Total Reward = -220\n",
      "Episode 226: Total Reward = 471\n",
      "Episode 227: Total Reward = 471\n",
      "Episode 228: Total Reward = -268\n",
      "Episode 229: Total Reward = -240\n",
      "Episode 230: Total Reward = -252\n",
      "Episode 231: Total Reward = 476\n",
      "Episode 232: Total Reward = -248\n",
      "Episode 233: Total Reward = 474\n",
      "Episode 234: Total Reward = -250\n",
      "Episode 235: Total Reward = 477\n",
      "Episode 236: Total Reward = 479\n",
      "Episode 237: Total Reward = -242\n",
      "Episode 238: Total Reward = -268\n",
      "Episode 239: Total Reward = -251\n",
      "Episode 240: Total Reward = -244\n",
      "Episode 241: Total Reward = -242\n",
      "Episode 242: Total Reward = 479\n",
      "Episode 243: Total Reward = 476\n",
      "Episode 244: Total Reward = -248\n",
      "Episode 245: Total Reward = 467\n",
      "Episode 246: Total Reward = -241\n",
      "Episode 247: Total Reward = 477\n",
      "Episode 248: Total Reward = -237\n",
      "Episode 249: Total Reward = 473\n",
      "Episode 250: Total Reward = -249\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "states = ['long', 'short']\n",
    "actions = ['buy', 'sell', 'hold']\n",
    "agent = QLearningAgent_mine(data, states, actions)\n",
    "agent.train(num_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "556f23f2-b574-47f8-96fb-91a88a9768f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.6410695 ,  6.2348898 ,  6.20885497],\n",
       "       [10.96925115,  9.87232604,  9.08574894]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "580b6398-8b9d-42e9-9cbe-02ce6dfadae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickled Q-matrix\n",
    "file_path = 'q_matrix.pkl'\n",
    "\n",
    "# Pickle the Q-matrix and save it to a file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(agent.Q, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
