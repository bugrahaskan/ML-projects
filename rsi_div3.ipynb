{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d10eb3-8d2f-406c-82e1-6ad5c916f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2938b777-dbfd-410a-83c5-974a08192511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RSI\n",
    "def calculate_rsi(df, column='Close', period=14):\n",
    "    delta = df[column].diff()\n",
    "    up_changes = delta.where(delta > 0, 0)\n",
    "    down_changes = -delta.where(delta < 0, 0)\n",
    "\n",
    "    if len(df) < period:\n",
    "        # Not enough data toac calculate RSI\n",
    "        return pd.Series([np.nan] * len(df), index=df.index)\n",
    "\n",
    "    # Calculate initial averages of gains and losses\n",
    "    initial_avg_up = up_changes.rolling(window=period).mean().dropna().iloc[0]\n",
    "    initial_avg_down = down_changes.rolling(window=period).mean().dropna().iloc[0]\n",
    "\n",
    "    # Lists to hold subsequent smoothed averages\n",
    "    avg_up = [initial_avg_up]\n",
    "    avg_down = [initial_avg_down]\n",
    "\n",
    "    # Calculate subsequent averages using Wilder's smoothing method\n",
    "    for i in range(period, len(up_changes)):\n",
    "        avg_up.append((avg_up[-1] * (period - 1) + up_changes.iloc[i]) / period)\n",
    "        avg_down.append((avg_down[-1] * (period - 1) + down_changes.iloc[i]) / period)\n",
    "\n",
    "    avg_up_series = pd.Series(avg_up, index=df.index[period - 1:])\n",
    "    avg_down_series = pd.Series(avg_down, index=df.index[period - 1:])\n",
    "\n",
    "    # Calculate RSI\n",
    "    rs = avg_up_series / avg_down_series\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Prepend NaNs for the initial period where RSI is not available\n",
    "    rsi = pd.concat([pd.Series([np.nan] * (period - 1), index=df.index[:period - 1]), rsi])\n",
    "\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26deb941-97a9-49d3-9516-b7195395d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get historical data for a ticker\n",
    "start = '2023-01-01'\n",
    "end = '2024-01-01'  # This can be None if you want data up to the current date\n",
    "\n",
    "def get_ticker_data(tickerSymbol, start, end=None, interval='1d'):\n",
    "    tickerData = yf.Ticker(tickerSymbol)\n",
    "    # Fetch historical data within the specified date range\n",
    "    df = tickerData.history(start=start, end=end, interval=interval, auto_adjust=False)\n",
    "\n",
    "    from talib import RSI\n",
    "    df['RSI'] = RSI(df['Close'], timeperiod=14)\n",
    "    df['RSI'] = df['RSI'].shift(1)\n",
    "\n",
    "    from talib import MA, SMA, EMA, WMA\n",
    "    df['MA'] = MA(df['Close'], timeperiod=9)\n",
    "    df['MA'] = df['MA'].shift(1)\n",
    "    df['SMA'] = SMA(df['Close'], timeperiod=9)\n",
    "    df['SMA'] = df['SMA'].shift(1)\n",
    "    df['WMA'] = WMA(df['Close'], timeperiod=9)\n",
    "    df['WMA'] = df['WMA'].shift(1)\n",
    "\n",
    "    from talib import MACD\n",
    "    df['macd'], df['signal'], df['hist'] = MACD(df['Close'])\n",
    "    df['macd'] = df['macd'].shift(1)\n",
    "    df['signal'] = df['signal'].shift(1)\n",
    "    df['hist'] = df['hist'].shift(1)\n",
    "\n",
    "    from talib import ADX\n",
    "    df['adx'] = ADX(df['High'], df['Low'], df['Close'])\n",
    "    df['adx'] = df['adx'].shift(1)\n",
    "    \n",
    "    from talib import ATR\n",
    "    df['atr'] = ATR(high=df['High'], low=df['Low'], close=df['Close'], timeperiod=14)\n",
    "    df['atr'] = df['atr'].shift(1)\n",
    "    \n",
    "    from talib import SAR\n",
    "    df['sar'] = SAR(high=df['High'], low=df['Low'], acceleration=0.02, maximum=0.2)\n",
    "    df['sar'] = df['sar'].shift(1)\n",
    "    \n",
    "    from talib import TEMA\n",
    "    df['tema'] = TEMA(df['Close'], timeperiod=14)\n",
    "    df['tema'] = df['tema'].shift(1)\n",
    "    \n",
    "    from talib import ROC\n",
    "    df['roc'] = ROC(df['Close'], timeperiod=14)\n",
    "    df['roc'] = df['roc'].shift(1)\n",
    "    \n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['EOM'] = df['Date'] == df.groupby(['Year', 'Month'])['Date'].transform('max')\n",
    "    # No change to the data processing code that follows\n",
    "\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#   # Define the path for the data directory\n",
    "#    data_directory = \"/content/data\"\n",
    "#    # Create the directory if it does not exist\n",
    "#    if not os.path.exists(data_directory):\n",
    "#        os.makedirs(data_directory)\n",
    "\n",
    "#    # Define the full path for the CSV file within the data directory\n",
    "#    raw_data_filename = os.path.join(data_directory, f'{tickerSymbol}_raw_data.csv')\n",
    "#    # Save the DataFrame to CSV in the specified directory\n",
    "#    df.to_csv(raw_data_filename, index=True)  # Include the datetime index in the CSV\n",
    "\n",
    "#    print(f\"Raw data for {tickerSymbol} saved to {raw_data_filename}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7c14e5-818c-4b38-8299-c7797b7cbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_ticker_data('KCHOL.IS', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee49e97a-ae7b-4cbe-9d8c-415d1292633e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MA</th>\n",
       "      <th>...</th>\n",
       "      <th>hist</th>\n",
       "      <th>adx</th>\n",
       "      <th>atr</th>\n",
       "      <th>sar</th>\n",
       "      <th>tema</th>\n",
       "      <th>roc</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>EOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-03 00:00:00+03:00</th>\n",
       "      <td>80.150002</td>\n",
       "      <td>82.800003</td>\n",
       "      <td>77.199997</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>77.165901</td>\n",
       "      <td>31451178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.372192</td>\n",
       "      <td>76.983332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714504</td>\n",
       "      <td>18.108116</td>\n",
       "      <td>3.710712</td>\n",
       "      <td>68.871956</td>\n",
       "      <td>79.212208</td>\n",
       "      <td>5.424839</td>\n",
       "      <td>2023-03-03 00:00:00+03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:00:00+03:00</th>\n",
       "      <td>79.400002</td>\n",
       "      <td>84.650002</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>82.642822</td>\n",
       "      <td>31118918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.517115</td>\n",
       "      <td>77.294444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651378</td>\n",
       "      <td>16.910218</td>\n",
       "      <td>3.845662</td>\n",
       "      <td>69.425078</td>\n",
       "      <td>79.499743</td>\n",
       "      <td>14.430754</td>\n",
       "      <td>2023-03-06 00:00:00+03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 00:00:00+03:00</th>\n",
       "      <td>84.800003</td>\n",
       "      <td>87.199997</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.153809</td>\n",
       "      <td>29398907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.573139</td>\n",
       "      <td>78.327777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935577</td>\n",
       "      <td>16.095386</td>\n",
       "      <td>3.981686</td>\n",
       "      <td>70.227573</td>\n",
       "      <td>81.632678</td>\n",
       "      <td>28.030303</td>\n",
       "      <td>2023-03-07 00:00:00+03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 00:00:00+03:00</th>\n",
       "      <td>84.099998</td>\n",
       "      <td>89.900002</td>\n",
       "      <td>83.750000</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>87.532928</td>\n",
       "      <td>25534993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.464306</td>\n",
       "      <td>79.338888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031154</td>\n",
       "      <td>15.953463</td>\n",
       "      <td>3.925851</td>\n",
       "      <td>71.381368</td>\n",
       "      <td>83.013044</td>\n",
       "      <td>10.817937</td>\n",
       "      <td>2023-03-08 00:00:00+03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 00:00:00+03:00</th>\n",
       "      <td>89.500000</td>\n",
       "      <td>89.849998</td>\n",
       "      <td>87.250000</td>\n",
       "      <td>87.550003</td>\n",
       "      <td>85.625793</td>\n",
       "      <td>17048208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.415553</td>\n",
       "      <td>80.938889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384051</td>\n",
       "      <td>16.398842</td>\n",
       "      <td>4.084719</td>\n",
       "      <td>72.963231</td>\n",
       "      <td>85.908706</td>\n",
       "      <td>19.412947</td>\n",
       "      <td>2023-03-09 00:00:00+03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-25 00:00:00+03:00</th>\n",
       "      <td>140.399994</td>\n",
       "      <td>140.600006</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>6084344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.547464</td>\n",
       "      <td>142.655557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054417</td>\n",
       "      <td>11.709525</td>\n",
       "      <td>3.829402</td>\n",
       "      <td>138.498674</td>\n",
       "      <td>143.059410</td>\n",
       "      <td>-1.610646</td>\n",
       "      <td>2023-12-25 00:00:00+03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26 00:00:00+03:00</th>\n",
       "      <td>138.100006</td>\n",
       "      <td>139.199997</td>\n",
       "      <td>136.100006</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>8821245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.443390</td>\n",
       "      <td>142.477778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>11.726466</td>\n",
       "      <td>3.813017</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>141.000224</td>\n",
       "      <td>-5.517241</td>\n",
       "      <td>2023-12-26 00:00:00+03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27 00:00:00+03:00</th>\n",
       "      <td>137.500000</td>\n",
       "      <td>138.300003</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>9411433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.414835</td>\n",
       "      <td>142.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.525972</td>\n",
       "      <td>11.968581</td>\n",
       "      <td>3.762086</td>\n",
       "      <td>148.760000</td>\n",
       "      <td>139.632231</td>\n",
       "      <td>-3.032442</td>\n",
       "      <td>2023-12-27 00:00:00+03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 00:00:00+03:00</th>\n",
       "      <td>136.199997</td>\n",
       "      <td>141.800003</td>\n",
       "      <td>136.199997</td>\n",
       "      <td>141.300003</td>\n",
       "      <td>141.300003</td>\n",
       "      <td>10027634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.257134</td>\n",
       "      <td>141.622223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715083</td>\n",
       "      <td>12.395355</td>\n",
       "      <td>3.707652</td>\n",
       "      <td>148.253600</td>\n",
       "      <td>138.101821</td>\n",
       "      <td>-4.628335</td>\n",
       "      <td>2023-12-28 00:00:00+03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 00:00:00+03:00</th>\n",
       "      <td>141.699997</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>141.800003</td>\n",
       "      <td>141.800003</td>\n",
       "      <td>9179187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.946163</td>\n",
       "      <td>140.877779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>11.648893</td>\n",
       "      <td>3.857105</td>\n",
       "      <td>147.476384</td>\n",
       "      <td>138.835634</td>\n",
       "      <td>-0.352609</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2023-03-03 00:00:00+03:00   80.150002   82.800003   77.199997   78.900002   \n",
       "2023-03-06 00:00:00+03:00   79.400002   84.650002   78.900002   84.500000   \n",
       "2023-03-07 00:00:00+03:00   84.800003   87.199997   84.000000   84.000000   \n",
       "2023-03-08 00:00:00+03:00   84.099998   89.900002   83.750000   89.500000   \n",
       "2023-03-09 00:00:00+03:00   89.500000   89.849998   87.250000   87.550003   \n",
       "...                               ...         ...         ...         ...   \n",
       "2023-12-25 00:00:00+03:00  140.399994  140.600006  137.000000  137.000000   \n",
       "2023-12-26 00:00:00+03:00  138.100006  139.199997  136.100006  137.500000   \n",
       "2023-12-27 00:00:00+03:00  137.500000  138.300003  135.300003  136.000000   \n",
       "2023-12-28 00:00:00+03:00  136.199997  141.800003  136.199997  141.300003   \n",
       "2023-12-29 00:00:00+03:00  141.699997  142.500000  139.500000  141.800003   \n",
       "\n",
       "                            Adj Close    Volume  Dividends  Stock Splits  \\\n",
       "Date                                                                       \n",
       "2023-03-03 00:00:00+03:00   77.165901  31451178        0.0           0.0   \n",
       "2023-03-06 00:00:00+03:00   82.642822  31118918        0.0           0.0   \n",
       "2023-03-07 00:00:00+03:00   82.153809  29398907        0.0           0.0   \n",
       "2023-03-08 00:00:00+03:00   87.532928  25534993        0.0           0.0   \n",
       "2023-03-09 00:00:00+03:00   85.625793  17048208        0.0           0.0   \n",
       "...                               ...       ...        ...           ...   \n",
       "2023-12-25 00:00:00+03:00  137.000000   6084344        0.0           0.0   \n",
       "2023-12-26 00:00:00+03:00  137.500000   8821245        0.0           0.0   \n",
       "2023-12-27 00:00:00+03:00  136.000000   9411433        0.0           0.0   \n",
       "2023-12-28 00:00:00+03:00  141.300003  10027634        0.0           0.0   \n",
       "2023-12-29 00:00:00+03:00  141.800003   9179187        0.0           0.0   \n",
       "\n",
       "                                 RSI          MA  ...      hist        adx  \\\n",
       "Date                                              ...                        \n",
       "2023-03-03 00:00:00+03:00  56.372192   76.983332  ...  0.714504  18.108116   \n",
       "2023-03-06 00:00:00+03:00  52.517115   77.294444  ...  0.651378  16.910218   \n",
       "2023-03-07 00:00:00+03:00  61.573139   78.327777  ...  0.935577  16.095386   \n",
       "2023-03-08 00:00:00+03:00  60.464306   79.338888  ...  1.031154  15.953463   \n",
       "2023-03-09 00:00:00+03:00  67.415553   80.938889  ...  1.384051  16.398842   \n",
       "...                              ...         ...  ...       ...        ...   \n",
       "2023-12-25 00:00:00+03:00  46.547464  142.655557  ...  0.054417  11.709525   \n",
       "2023-12-26 00:00:00+03:00  41.443390  142.477778  ... -0.332231  11.726466   \n",
       "2023-12-27 00:00:00+03:00  42.414835  142.566667  ... -0.525972  11.968581   \n",
       "2023-12-28 00:00:00+03:00  40.257134  141.622223  ... -0.715083  12.395355   \n",
       "2023-12-29 00:00:00+03:00  49.946163  140.877779  ... -0.455790  11.648893   \n",
       "\n",
       "                                atr         sar        tema        roc  \\\n",
       "Date                                                                     \n",
       "2023-03-03 00:00:00+03:00  3.710712   68.871956   79.212208   5.424839   \n",
       "2023-03-06 00:00:00+03:00  3.845662   69.425078   79.499743  14.430754   \n",
       "2023-03-07 00:00:00+03:00  3.981686   70.227573   81.632678  28.030303   \n",
       "2023-03-08 00:00:00+03:00  3.925851   71.381368   83.013044  10.817937   \n",
       "2023-03-09 00:00:00+03:00  4.084719   72.963231   85.908706  19.412947   \n",
       "...                             ...         ...         ...        ...   \n",
       "2023-12-25 00:00:00+03:00  3.829402  138.498674  143.059410  -1.610646   \n",
       "2023-12-26 00:00:00+03:00  3.813017  149.000000  141.000224  -5.517241   \n",
       "2023-12-27 00:00:00+03:00  3.762086  148.760000  139.632231  -3.032442   \n",
       "2023-12-28 00:00:00+03:00  3.707652  148.253600  138.101821  -4.628335   \n",
       "2023-12-29 00:00:00+03:00  3.857105  147.476384  138.835634  -0.352609   \n",
       "\n",
       "                                               Date  Month  Year    EOM  \n",
       "Date                                                                     \n",
       "2023-03-03 00:00:00+03:00 2023-03-03 00:00:00+03:00      3  2023  False  \n",
       "2023-03-06 00:00:00+03:00 2023-03-06 00:00:00+03:00      3  2023  False  \n",
       "2023-03-07 00:00:00+03:00 2023-03-07 00:00:00+03:00      3  2023  False  \n",
       "2023-03-08 00:00:00+03:00 2023-03-08 00:00:00+03:00      3  2023  False  \n",
       "2023-03-09 00:00:00+03:00 2023-03-09 00:00:00+03:00      3  2023  False  \n",
       "...                                             ...    ...   ...    ...  \n",
       "2023-12-25 00:00:00+03:00 2023-12-25 00:00:00+03:00     12  2023  False  \n",
       "2023-12-26 00:00:00+03:00 2023-12-26 00:00:00+03:00     12  2023  False  \n",
       "2023-12-27 00:00:00+03:00 2023-12-27 00:00:00+03:00     12  2023  False  \n",
       "2023-12-28 00:00:00+03:00 2023-12-28 00:00:00+03:00     12  2023  False  \n",
       "2023-12-29 00:00:00+03:00 2023-12-29 00:00:00+03:00     12  2023   True  \n",
       "\n",
       "[209 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44052818-6cc1-40c6-9d5c-cdbb8b701603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create input sequences and targets\n",
    "def create_sequences(features, target, seq_length):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X_seq.append(features[i:i+seq_length])  # Input sequence\n",
    "        y_seq.append(target[i+seq_length]) # Target value (next data point)\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0393155-33a3-4f07-886b-dd246ba7d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_input = df[['Close', 'MA', 'SMA', 'macd', 'signal', 'hist', 'adx', 'atr', 'sar', 'tema', 'roc']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_input)\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "target_scaled = scaler_target.fit_transform(df[['Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636593d3-63bd-441b-b35a-195d732ecd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4  # Number of time steps in each sequence\n",
    "num_features = df_input.shape[1]\n",
    "X_features = df_scaled\n",
    "y_target = target_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761e6921-2ef6-4dc2-982c-6894403ef92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b, y_b = create_sequences(df_scaled, target_scaled, seq_length)\n",
    "X_b = X_b.reshape(X_b.shape[0], seq_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8b8930a-7a58-4976-99e5-286012eb4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 07:39:15.263685: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-05 07:39:15.341651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-05 07:39:15.341745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-05 07:39:15.345294: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-05 07:39:15.360152: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-05 07:39:17.296837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickled model from file\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12cfd30a-dfce-44fd-924e-05be2f0625dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_b)\n",
    "y_pred = scaler_target.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc82f0a-9ec6-469e-9f34-bdabb0e5539a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.124466, 209)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[2][0], len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3c12ee-df3d-404e-807c-9991303380f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_manual_peaks(df, y_pred):\n",
    "    peaks = []\n",
    "    for i in range(seq_length, len(df)-1):\n",
    "        if df['Close'].iloc[i] > df['Close'].iloc[i-1] and df['Close'].iloc[i] > y_pred[i+1-seq_length][0]:\n",
    "            peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "def find_manual_troughs(df, y_pred):\n",
    "    troughs = []\n",
    "    for i in range(seq_length, len(df)-1):\n",
    "        if df['Close'].iloc[i] < df['Close'].iloc[i-1] and df['Close'].iloc[i] < y_pred[i+1-seq_length][0]:\n",
    "            troughs.append(i)\n",
    "    return troughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80428aa5-c53a-4fb3-b328-c8ffc2017d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_divergences(df, tolerance=0.01):\n",
    "    divergences = []\n",
    "\n",
    "    peaks_indices = find_manual_peaks(df, y_pred)\n",
    "    troughs_indices = find_manual_troughs(df, y_pred)\n",
    "\n",
    "    def process_divergence(indices, find_highs):\n",
    "        if len(indices) >= 2:\n",
    "            for i in range(len(indices) - 1):\n",
    "                # Fetch the index, price, and RSI values for the peaks/troughs\n",
    "                idx1, idx2 = indices[i], indices[i+1]\n",
    "                price1, price2 = df['Close'].iloc[idx1], df['Close'].iloc[idx2]\n",
    "                rsi1, rsi2 = df['RSI'].iloc[idx1], df['RSI'].iloc[idx2]\n",
    "\n",
    "                if find_highs:\n",
    "                    if price1 > price2 and rsi1 > rsi2:\n",
    "                        divergences.append(('Bearish', df.index[idx1], df.index[idx2], price1, price2, rsi1, rsi2))\n",
    "                else:\n",
    "                    if price1 < price2 and rsi1 < rsi2:\n",
    "                        divergences.append(('Bullish', df.index[idx1], df.index[idx2], price1, price2, rsi1, rsi2))\n",
    "\n",
    "    # Process both peaks and troughs\n",
    "    process_divergence(peaks_indices, True)\n",
    "    process_divergence(troughs_indices, False)\n",
    "\n",
    "    return divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ca103a-ad78-4af5-912f-08189edb438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tickers(tickerSymbols):\n",
    "    all_divergences = []\n",
    "    for ticker in tickerSymbols:\n",
    "        #try:\n",
    "        print(f\"Processing {ticker}...\")\n",
    "        df = get_ticker_data(ticker, start, end)\n",
    "        # Shift the close prices up to get the next day's close\n",
    "        df['Next Bar Close'] = df['Close'].shift(-1)\n",
    "\n",
    "        #if len(df) >= 14:  # Ensure there's enough data to calculate RSI\n",
    "        divergences = detect_divergences(df)\n",
    "\n",
    "        # Append divergence details, ensuring correct alignment with the DataFrame columns\n",
    "        for divergence in divergences:\n",
    "            # Find the index for the next bar close\n",
    "            idx2 = divergence[2]  # This is the index for 'Second Date'\n",
    "            next_bar_close = df.at[idx2, 'Next Bar Close'] if idx2 in df.index else np.nan\n",
    "\n",
    "            all_divergences.append(\n",
    "                (\n",
    "                    ticker,  # Ticker\n",
    "                    divergence[0],  # Type of divergence\n",
    "                    divergence[1],  # First Date\n",
    "                    divergence[2],  # Second Date\n",
    "                    divergence[3],  # First Price\n",
    "                    divergence[4],  # Second Price\n",
    "                    divergence[3],  # Use First Price again as \"First Close Price\"\n",
    "                    divergence[4],  # Use Second Price again as \"Second Close Price\"\n",
    "                    divergence[5],  # First RSI\n",
    "                    divergence[6],  # Second RSI\n",
    "                    df['Close'].iloc[-1],  # Final Close Price\n",
    "                    df.index[-1],  # Final Date\n",
    "                    next_bar_close   # Next Bar Close\n",
    "                )\n",
    "            )\n",
    "        #except Exception as e:\n",
    "        #    print(f\"Error processing {ticker}: {e}\")\n",
    "    return all_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28b52a93-1389-4c52-9bc4-4814c4fe8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your tickers file\n",
    "#file_path = \"/content/tickers.txt\"\n",
    "file_path = \"tickers-Turkey.txt\"\n",
    "\n",
    "# Initialize an empty list to hold the ticker symbols\n",
    "tickerSymbols = []\n",
    "\n",
    "# Open the file and read each line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip newline characters and any leading/trailing whitespace\n",
    "        ticker = line.strip()\n",
    "        # Add the ticker symbol to the list\n",
    "        tickerSymbols.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81be630e-eb31-4a29-9edc-a25e347676cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Symbol...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYMBOL: No timezone found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ISKUR.IS...\n",
      "Processing QNBFB.IS...\n",
      "Processing KCHOL.IS...\n",
      "Processing FROTO.IS...\n",
      "Processing THYAO.IS...\n",
      "Processing TUPRS.IS...\n",
      "Processing ISCTR.IS...\n",
      "Processing ISBTR.IS...\n",
      "Processing ISATR.IS...\n",
      "Processing GARAN.IS...\n",
      "Processing ASELS.IS...\n",
      "Processing BIMAS.IS...\n",
      "Processing AKBNK.IS...\n",
      "Processing ENKAI.IS...\n",
      "Processing SASA.IS...\n",
      "Processing KENT.IS...\n",
      "Processing YKBNK.IS...\n",
      "Processing SAHOL.IS...\n",
      "Processing QNBFL.IS...\n",
      "Processing CCOLA.IS...\n",
      "Processing EREGL.IS...\n",
      "Processing SISE.IS...\n",
      "Processing VAKBN.IS...\n",
      "Processing TCELL.IS...\n",
      "Processing TOASO.IS...\n",
      "Processing ISDMR.IS...\n",
      "Processing BRYAT.IS...\n",
      "Processing TTKOM.IS...\n",
      "Processing HALKB.IS...\n",
      "Processing ARCLK.IS...\n",
      "Processing BRSAN.IS...\n",
      "Processing TTRAK.IS...\n",
      "Processing AEFES.IS...\n",
      "Processing MGROS.IS...\n",
      "Processing OYAKC.IS...\n",
      "Processing KLNMA.IS...\n",
      "Processing PGSUS.IS...\n",
      "Processing POLTK.IS...\n",
      "Processing KOZAL.IS...\n",
      "Processing ENJSA.IS...\n",
      "Processing AGHOL.IS...\n",
      "Processing TAVHL.IS...\n",
      "Processing GUBRF.IS...\n",
      "Processing PETKM.IS...\n",
      "Processing TURSG.IS...\n",
      "Processing OTKAR.IS...\n",
      "Processing ALARK.IS...\n",
      "Processing DOAS.IS...\n",
      "Processing ISMEN.IS...\n",
      "Processing CMENT.IS...\n",
      "Processing RAYSG.IS...\n",
      "Processing DOCO.IS...\n",
      "Processing KONTR.IS...\n",
      "Processing KONYA.IS...\n",
      "Processing AKSEN.IS...\n",
      "Processing EGEEN.IS...\n",
      "Processing HEKTS.IS...\n",
      "Processing NUHCM.IS...\n",
      "Processing TRGYO.IS...\n",
      "Processing ULKER.IS...\n",
      "Processing EKGYO.IS...\n",
      "Processing BRISA.IS...\n",
      "Processing AGROT.IS...\n",
      "Processing SOKM.IS...\n",
      "Processing MIATK.IS...\n",
      "Processing ANSGR.IS...\n",
      "Processing SMRTG.IS...\n",
      "Processing ECILC.IS...\n",
      "Processing SELEC.IS...\n",
      "Processing AYGAZ.IS...\n",
      "Processing ALFAS.IS...\n",
      "Processing MPARK.IS...\n",
      "Processing CWENE.IS...\n",
      "Processing EUPWR.IS...\n",
      "Processing DOHOL.IS...\n",
      "Processing BFREN.IS...\n",
      "Processing TABGD.IS...\n",
      "Processing KLSER.IS...\n",
      "Processing AKSA.IS...\n",
      "Processing AHGAZ.IS...\n",
      "Processing GESAN.IS...\n",
      "Processing ZRGYO.IS...\n",
      "Processing CIMSA.IS...\n",
      "Processing CLEBI.IS...\n",
      "Processing VESBE.IS...\n",
      "Processing KSTUR.IS...\n",
      "Processing MAVI.IS...\n",
      "Processing AKCNS.IS...\n",
      "Processing TBORG.IS...\n",
      "Processing KRDMA.IS...\n",
      "Processing KRDMD.IS...\n",
      "Processing KRDMB.IS...\n",
      "Processing ZOREN.IS...\n",
      "Processing AKFYE.IS...\n",
      "Processing ECZYT.IS...\n",
      "Processing VESTL.IS...\n",
      "Processing MIPAZ.IS...\n",
      "Processing KAYSE.IS...\n",
      "Processing TSKB.IS...\n",
      "Processing MRSHL.IS...\n",
      "Processing GENIL.IS...\n",
      "Processing ANHYT.IS...\n",
      "Processing BTCIM.IS...\n",
      "Processing KORDS.IS...\n",
      "Processing ENERY.IS...\n",
      "Processing YEOTK.IS...\n",
      "Processing CRFSA.IS...\n",
      "Processing KOZAA.IS...\n",
      "Processing SDTTR.IS...\n",
      "Processing AYDEM.IS...\n",
      "Processing AYCES.IS...\n",
      "Processing YBTAS.IS...\n",
      "Processing PATEK.IS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PATEK.IS: Data doesn't exist for startDate = 1672520400, endDate = 1704056400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALCAR.IS...\n",
      "Processing VERUS.IS...\n",
      "Processing TMSN.IS...\n",
      "Processing EGPRO.IS...\n",
      "Processing ASUZU.IS...\n",
      "Processing BJKAS.IS...\n",
      "Processing JANTS.IS...\n",
      "Processing IZENR.IS...\n",
      "Processing LMKDC.IS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LMKDC.IS: Data doesn't exist for startDate = 1672520400, endDate = 1704056400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MAGEN.IS...\n",
      "Processing CANTE.IS...\n",
      "Processing TKFEN.IS...\n",
      "Processing BANVT.IS...\n",
      "Processing SARKY.IS...\n",
      "Processing BIENY.IS...\n",
      "Processing YYLGD.IS...\n",
      "Processing ISGYO.IS...\n",
      "Processing DEVA.IS...\n",
      "Processing KMPUR.IS...\n",
      "Processing SRVGY.IS...\n",
      "Processing TETMT.IS...\n",
      "Processing PEKGY.IS...\n",
      "Processing ULUSE.IS...\n",
      "Processing ODAS.IS...\n",
      "Processing ERCB.IS...\n",
      "Processing OYYAT.IS...\n",
      "Processing GWIND.IS...\n",
      "Processing NATEN.IS...\n",
      "Processing INGRM.IS...\n",
      "Processing OZKGY.IS...\n",
      "Processing MEGMT.IS...\n",
      "Processing ADEL.IS...\n",
      "Processing RYSAS.IS...\n",
      "Processing ICBCT.IS...\n",
      "Processing DGGYO.IS...\n",
      "Processing KLKIM.IS...\n",
      "Processing NTHOL.IS...\n",
      "Processing GARFA.IS...\n",
      "Processing DAPGM.IS...\n",
      "Processing AKSGY.IS...\n",
      "Processing VAKKO.IS...\n",
      "Processing TUKAS.IS...\n",
      "Processing UFUK.IS...\n",
      "Processing BERA.IS...\n",
      "Processing AGESA.IS...\n",
      "Processing KAREL.IS...\n",
      "Processing SNPAM.IS...\n",
      "Processing BUCIM.IS...\n",
      "Processing ATATP.IS...\n",
      "Processing DOKTA.IS...\n",
      "Processing RYGYO.IS...\n",
      "Processing PSGYO.IS...\n",
      "Processing IPEKE.IS...\n",
      "Processing QUAGR.IS...\n",
      "Processing YGGYO.IS...\n",
      "Processing HLGYO.IS...\n",
      "Processing POLHO.IS...\n",
      "Processing ALBRK.IS...\n",
      "Processing TEZOL.IS...\n",
      "Processing INVEO.IS...\n",
      "Processing KARTN.IS...\n",
      "Processing AKFGY.IS...\n",
      "Processing CATES.IS...\n",
      "Processing GOZDE.IS...\n",
      "Processing HEDEF.IS...\n",
      "Processing IZMDC.IS...\n",
      "Processing AKGRT.IS...\n",
      "Processing VRGYO.IS...\n",
      "Processing KARSN.IS...\n",
      "Processing BORSK.IS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BORSK.IS: Data doesn't exist for startDate = 1672520400, endDate = 1704056400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ARDYZ.IS...\n",
      "Processing TKNSA.IS...\n",
      "Processing PARSN.IS...\n",
      "Processing FENER.IS...\n",
      "Processing PKENT.IS...\n",
      "Processing LOGO.IS...\n",
      "Processing AKMGY.IS...\n",
      "Processing SUNTK.IS...\n",
      "Processing BASCM.IS...\n",
      "Processing PENTA.IS...\n",
      "Processing INDES.IS...\n",
      "Processing SKBNK.IS...\n",
      "Processing HTTBT.IS...\n",
      "Processing GOKNR.IS...\n",
      "Processing GLYHO.IS...\n",
      "Processing KERVT.IS...\n",
      "Processing PRKAB.IS...\n",
      "Processing BSOKE.IS...\n",
      "Processing KLGYO.IS...\n",
      "Processing TNZTP.IS...\n",
      "Processing CMBTN.IS...\n",
      "Processing AYEN.IS...\n",
      "Processing ATAKP.IS...\n",
      "Processing ESEN.IS...\n",
      "Processing GEDIK.IS...\n",
      "Processing KRVGD.IS...\n",
      "Processing MNDTR.IS...\n",
      "Processing GSRAY.IS...\n",
      "Processing ISFIN.IS...\n",
      "Processing RALYH.IS...\n",
      "Processing GLCVY.IS...\n",
      "Processing KZBGY.IS...\n",
      "Processing PNLSN.IS...\n",
      "Processing TRCAS.IS...\n",
      "Processing BOSSA.IS...\n",
      "Processing ALGYO.IS...\n",
      "Processing KONKA.IS...\n",
      "Processing ALKA.IS...\n",
      "Processing INTEM.IS...\n",
      "Processing MAALT.IS...\n",
      "Processing SAYAS.IS...\n",
      "Processing BRLSM.IS...\n",
      "Processing GOODY.IS...\n",
      "Processing SONME.IS...\n",
      "Processing TSGYO.IS...\n",
      "Processing ALKIM.IS...\n",
      "Processing ORMA.IS...\n",
      "Processing VKGYO.IS...\n",
      "Processing ORGE.IS...\n",
      "Processing DESA.IS...\n",
      "Processing SNGYO.IS...\n",
      "Processing ULUUN.IS...\n",
      "Processing TURGG.IS...\n",
      "Processing VAKFN.IS...\n",
      "Processing GOLTS.IS...\n",
      "Processing FONET.IS...\n",
      "Processing YAPRK.IS...\n",
      "Processing CEMTS.IS...\n",
      "Processing ERBOS.IS...\n",
      "Processing KUYAS.IS...\n",
      "Processing NETAS.IS...\n",
      "Processing VBTYZ.IS...\n",
      "Processing SUWEN.IS...\n",
      "Processing AFYON.IS...\n",
      "Processing LINK.IS...\n",
      "Processing ARENA.IS...\n",
      "Processing OSMEN.IS...\n",
      "Processing EGGUB.IS...\n",
      "Processing ISBIR.IS...\n",
      "Processing YUNSA.IS...\n",
      "Processing TATGD.IS...\n",
      "Processing FMIZP.IS...\n",
      "Processing A1CAP.IS...\n",
      "Processing ALCTL.IS...\n",
      "Processing YATAS.IS...\n",
      "Processing MEDTR.IS...\n",
      "Processing PAMEL.IS...\n",
      "Processing PAPIL.IS...\n",
      "Processing BVSAN.IS...\n",
      "Processing PNSUT.IS...\n",
      "Processing DARDL.IS...\n",
      "Processing ANELE.IS...\n",
      "Processing AKENR.IS...\n",
      "Processing ESCOM.IS...\n",
      "Processing MEKAG.IS...\n",
      "Processing TSPOR.IS...\n",
      "Processing ATEKS.IS...\n",
      "Processing DGNMO.IS...\n",
      "Processing PETUN.IS...\n",
      "Processing CEMAS.IS...\n",
      "Processing SANKO.IS...\n",
      "Processing GSDHO.IS...\n",
      "Processing BAGFS.IS...\n",
      "Processing BIZIM.IS...\n",
      "Processing KUTPO.IS...\n",
      "Processing PRKME.IS...\n",
      "Processing PAGYO.IS...\n",
      "Processing KAPLM.IS...\n",
      "Processing INFO.IS...\n",
      "Processing GEREL.IS...\n",
      "Processing UNLU.IS...\n",
      "Processing KNFRT.IS...\n",
      "Processing SUMAS.IS...\n",
      "Processing BAKAB.IS...\n",
      "Processing MNDRS.IS...\n",
      "Processing CELHA.IS...\n",
      "Processing DYOBY.IS...\n",
      "Processing KFEIN.IS...\n",
      "Processing IEYHO.IS...\n",
      "Processing LUKSK.IS...\n",
      "Processing MERIT.IS...\n",
      "Processing ANGEN.IS...\n",
      "Processing ADESE.IS...\n",
      "Processing GENTS.IS...\n",
      "Processing HURGZ.IS...\n",
      "Processing OTTO.IS...\n",
      "Processing EGSER.IS...\n",
      "Processing KLMSN.IS...\n",
      "Processing USAK.IS...\n",
      "Processing PEGYO.IS...\n",
      "Processing MARTI.IS...\n",
      "Processing BYDNR.IS...\n",
      "Processing TLMAN.IS...\n",
      "Processing AGYO.IS...\n",
      "Processing ARSAN.IS...\n",
      "Processing VERTU.IS...\n",
      "Processing KATMR.IS...\n",
      "Processing DOFER.IS...\n",
      "Processing UZERB.IS...\n",
      "Processing DOBUR.IS...\n",
      "Processing GLRYH.IS...\n",
      "Processing LRSHO.IS...\n",
      "Processing SODSN.IS...\n",
      "Processing EMKEL.IS...\n",
      "Processing NUGYO.IS...\n",
      "Processing MARKA.IS...\n",
      "Processing LKMNH.IS...\n",
      "Processing ALMAD.IS...\n",
      "Processing TERA.IS...\n",
      "Processing TUCLK.IS...\n",
      "Processing BEYAZ.IS...\n",
      "Processing RUBNS.IS...\n",
      "Processing LIDFA.IS...\n",
      "Processing YKSLN.IS...\n",
      "Processing PINSU.IS...\n",
      "Processing KRONT.IS...\n",
      "Processing CUSAN.IS...\n",
      "Processing DZGYO.IS...\n",
      "Processing ZEDUR.IS...\n",
      "Processing SAMAT.IS...\n",
      "Processing DERHL.IS...\n",
      "Processing MSGYO.IS...\n",
      "Processing SANFM.IS...\n"
     ]
    }
   ],
   "source": [
    "# After generating all divergences\n",
    "all_divergences = process_tickers(tickerSymbols)\n",
    "\n",
    "# Create the DataFrame\n",
    "divergences_df = pd.DataFrame(all_divergences, columns=[\n",
    "    'Ticker', 'Type',\n",
    "    'First Date', 'Second Date',\n",
    "    'First Price', 'Second Price',\n",
    "    'First Close', 'Second Close',\n",
    "    'First RSI', 'Second RSI',\n",
    "    'Final Close', 'Final Date',\n",
    "    'Next Bar Close'  # Include the new column for Next Bar Close\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27932986-356f-4ce8-a379-828f00c873ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Type</th>\n",
       "      <th>First Date</th>\n",
       "      <th>Second Date</th>\n",
       "      <th>First Price</th>\n",
       "      <th>Second Price</th>\n",
       "      <th>First Close</th>\n",
       "      <th>Second Close</th>\n",
       "      <th>First RSI</th>\n",
       "      <th>Second RSI</th>\n",
       "      <th>Final Close</th>\n",
       "      <th>Final Date</th>\n",
       "      <th>Next Bar Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QNBFB.IS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2023-09-15 00:00:00+03:00</td>\n",
       "      <td>2023-09-19 00:00:00+03:00</td>\n",
       "      <td>202.800003</td>\n",
       "      <td>200.800003</td>\n",
       "      <td>202.800003</td>\n",
       "      <td>200.800003</td>\n",
       "      <td>81.865979</td>\n",
       "      <td>70.033613</td>\n",
       "      <td>287.750000</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>220.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QNBFB.IS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2023-09-29 00:00:00+03:00</td>\n",
       "      <td>2023-10-05 00:00:00+03:00</td>\n",
       "      <td>403.899994</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>403.899994</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>89.902639</td>\n",
       "      <td>60.538621</td>\n",
       "      <td>287.750000</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QNBFB.IS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2023-10-06 00:00:00+03:00</td>\n",
       "      <td>2023-10-10 00:00:00+03:00</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>333.600006</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>333.600006</td>\n",
       "      <td>64.310289</td>\n",
       "      <td>58.726868</td>\n",
       "      <td>287.750000</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>366.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QNBFB.IS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2023-10-11 00:00:00+03:00</td>\n",
       "      <td>2023-10-16 00:00:00+03:00</td>\n",
       "      <td>366.899994</td>\n",
       "      <td>346.799988</td>\n",
       "      <td>366.899994</td>\n",
       "      <td>346.799988</td>\n",
       "      <td>62.646142</td>\n",
       "      <td>56.534596</td>\n",
       "      <td>287.750000</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>346.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QNBFB.IS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2023-10-16 00:00:00+03:00</td>\n",
       "      <td>2023-10-19 00:00:00+03:00</td>\n",
       "      <td>346.799988</td>\n",
       "      <td>343.399994</td>\n",
       "      <td>346.799988</td>\n",
       "      <td>343.399994</td>\n",
       "      <td>56.534596</td>\n",
       "      <td>54.177929</td>\n",
       "      <td>287.750000</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>366.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8079</th>\n",
       "      <td>SANFM.IS</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2023-10-30 00:00:00+03:00</td>\n",
       "      <td>2023-11-07 00:00:00+03:00</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.639999</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.639999</td>\n",
       "      <td>68.050868</td>\n",
       "      <td>79.278339</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>36.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>SANFM.IS</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2023-11-09 00:00:00+03:00</td>\n",
       "      <td>2023-11-17 00:00:00+03:00</td>\n",
       "      <td>35.580002</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>35.580002</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>75.904030</td>\n",
       "      <td>83.600610</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>41.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8081</th>\n",
       "      <td>SANFM.IS</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2023-11-21 00:00:00+03:00</td>\n",
       "      <td>2023-11-27 00:00:00+03:00</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>48.520000</td>\n",
       "      <td>39.099998</td>\n",
       "      <td>48.520000</td>\n",
       "      <td>70.037833</td>\n",
       "      <td>76.607827</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>47.560001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8082</th>\n",
       "      <td>SANFM.IS</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2023-11-30 00:00:00+03:00</td>\n",
       "      <td>2023-12-06 00:00:00+03:00</td>\n",
       "      <td>46.599998</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>46.599998</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>72.118795</td>\n",
       "      <td>76.254074</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>SANFM.IS</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>2023-12-18 00:00:00+03:00</td>\n",
       "      <td>2023-12-22 00:00:00+03:00</td>\n",
       "      <td>41.360001</td>\n",
       "      <td>42.880001</td>\n",
       "      <td>41.360001</td>\n",
       "      <td>42.880001</td>\n",
       "      <td>48.577025</td>\n",
       "      <td>50.957064</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>2023-12-29 00:00:00+03:00</td>\n",
       "      <td>38.599998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8084 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ticker     Type                First Date               Second Date  \\\n",
       "0     QNBFB.IS  Bearish 2023-09-15 00:00:00+03:00 2023-09-19 00:00:00+03:00   \n",
       "1     QNBFB.IS  Bearish 2023-09-29 00:00:00+03:00 2023-10-05 00:00:00+03:00   \n",
       "2     QNBFB.IS  Bearish 2023-10-06 00:00:00+03:00 2023-10-10 00:00:00+03:00   \n",
       "3     QNBFB.IS  Bearish 2023-10-11 00:00:00+03:00 2023-10-16 00:00:00+03:00   \n",
       "4     QNBFB.IS  Bearish 2023-10-16 00:00:00+03:00 2023-10-19 00:00:00+03:00   \n",
       "...        ...      ...                       ...                       ...   \n",
       "8079  SANFM.IS  Bullish 2023-10-30 00:00:00+03:00 2023-11-07 00:00:00+03:00   \n",
       "8080  SANFM.IS  Bullish 2023-11-09 00:00:00+03:00 2023-11-17 00:00:00+03:00   \n",
       "8081  SANFM.IS  Bullish 2023-11-21 00:00:00+03:00 2023-11-27 00:00:00+03:00   \n",
       "8082  SANFM.IS  Bullish 2023-11-30 00:00:00+03:00 2023-12-06 00:00:00+03:00   \n",
       "8083  SANFM.IS  Bullish 2023-12-18 00:00:00+03:00 2023-12-22 00:00:00+03:00   \n",
       "\n",
       "      First Price  Second Price  First Close  Second Close  First RSI  \\\n",
       "0      202.800003    200.800003   202.800003    200.800003  81.865979   \n",
       "1      403.899994    324.000000   403.899994    324.000000  89.902639   \n",
       "2      337.000000    333.600006   337.000000    333.600006  64.310289   \n",
       "3      366.899994    346.799988   366.899994    346.799988  62.646142   \n",
       "4      346.799988    343.399994   346.799988    343.399994  56.534596   \n",
       "...           ...           ...          ...           ...        ...   \n",
       "8079    30.000000     36.639999    30.000000     36.639999  68.050868   \n",
       "8080    35.580002     43.000000    35.580002     43.000000  75.904030   \n",
       "8081    39.099998     48.520000    39.099998     48.520000  70.037833   \n",
       "8082    46.599998     51.000000    46.599998     51.000000  72.118795   \n",
       "8083    41.360001     42.880001    41.360001     42.880001  48.577025   \n",
       "\n",
       "      Second RSI  Final Close                Final Date  Next Bar Close  \n",
       "0      70.033613   287.750000 2023-12-29 00:00:00+03:00      220.800003  \n",
       "1      60.538621   287.750000 2023-12-29 00:00:00+03:00      337.000000  \n",
       "2      58.726868   287.750000 2023-12-29 00:00:00+03:00      366.899994  \n",
       "3      56.534596   287.750000 2023-12-29 00:00:00+03:00      346.799988  \n",
       "4      54.177929   287.750000 2023-12-29 00:00:00+03:00      366.399994  \n",
       "...          ...          ...                       ...             ...  \n",
       "8079   79.278339    39.119999 2023-12-29 00:00:00+03:00       36.400002  \n",
       "8080   83.600610    39.119999 2023-12-29 00:00:00+03:00       41.080002  \n",
       "8081   76.607827    39.119999 2023-12-29 00:00:00+03:00       47.560001  \n",
       "8082   76.254074    39.119999 2023-12-29 00:00:00+03:00       50.000000  \n",
       "8083   50.957064    39.119999 2023-12-29 00:00:00+03:00       38.599998  \n",
       "\n",
       "[8084 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divergences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db49369b-369a-4b08-8f86-73c67feb2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "divergences_df.to_csv('test-detected_divergences_for_multiple_stocks_with_next_bar_close.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08799a36-33d6-4d16-a9cb-5fb16e1914ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77478d04-3726-4b29-ad80-89146c60bde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9fe-5d17-4875-954a-c521acdd04e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891531d6-68ae-446a-a338-61fe4d21e51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
