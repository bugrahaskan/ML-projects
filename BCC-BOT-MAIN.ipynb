{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38376bda-0285-49c8-a1c9-6f1ec3d1f12b",
   "metadata": {},
   "source": [
    "# whole operation for a given symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a749fdbc-f69e-416d-80c6-ff839de035f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 07:05:45.934842: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-21 07:05:46.016438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 07:05:46.016513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 07:05:46.019634: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-21 07:05:46.034117: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-21 07:05:47.553972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup: Weigths for the best epoch has been loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import yfinance as yf\n",
    "\n",
    "class BCC:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db_name = 'positions.db'\n",
    "        self.create_positions_db()\n",
    "        self.DATA = dict()\n",
    "\n",
    "    ## Position's database\n",
    "    def create_positions_db(self, file_path = \"tickers-nasdaq.txt\"):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('''\n",
    "                        CREATE TABLE IF NOT EXISTS tickers (\n",
    "                            id INTEGER PRIMARY KEY,\n",
    "                            ticker TEXT NOT NULL\n",
    "                        );''')\n",
    "\n",
    "        tickerSymbols = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                tickerSymbols.append(line.strip())\n",
    "\n",
    "        for symbol in tickerSymbols:\n",
    "            cursor.execute('''INSERT INTO tickers (ticker) VALUES (?)''',\n",
    "                           (str(symbol),)\n",
    "                          )\n",
    "            connection.commit()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                            CREATE TABLE IF NOT EXISTS data_{} (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                ticker_id TEXT NOT NULL,\n",
    "                                date DATETIME,\n",
    "                                close FLOAT,\n",
    "                                pred FLOAT,\n",
    "                                induced_high FLOAT,\n",
    "                                induced_low FLOAT,\n",
    "                                position INTEGER,\n",
    "                                entry_price FLOAT,\n",
    "                                exit_price FLOAT,\n",
    "                                duration INTEGER,\n",
    "                                gross_pnl FLOAT,\n",
    "                                fee FLOAT,\n",
    "                                net_pnl FLOAT,\n",
    "                                FOREIGN KEY (ticker_id) REFERENCES tickers (id)\n",
    "                            );'''.format(symbol))\n",
    "    \n",
    "        self.commit_close_db()\n",
    "\n",
    "    def insert_data_db(self, symbol, data: dict):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('SELECT id FROM tickers WHERE ticker = ?', (data[symbol][\"ticker\"],))\n",
    "        ticker_id = cursor.fetchone()\n",
    "        ticker_id = ticker_id[0]\n",
    "\n",
    "        if data[symbol][\"entry_price\"] == None and data[symbol][\"exit_price\"] == None:\n",
    "            cursor.execute(\"INSERT OR REPLACE INTO data_{} (ticker_id, date, close, pred, induced_high, induced_low, position) VALUES (?,?,?,?,?,?,?)\".format(data[symbol][\"ticker\"]),\n",
    "                            (\n",
    "                                int(ticker_id),\n",
    "                                str(data[symbol][\"date\"]),\n",
    "                                float(data[symbol][\"close\"]),\n",
    "                                float(data[symbol][\"pred\"]),\n",
    "                                float(data[symbol][\"induced_high\"]),\n",
    "                                float(data[symbol][\"induced_low\"]),\n",
    "                                float(data[symbol][\"position\"]),\n",
    "                                #float(data[symbol][\"entry_price\"]),\n",
    "                                #float(data[symbol][\"exit_price\"]),\n",
    "                                #int(data[symbol][\"duration\"]),\n",
    "                                #float(data[symbol][\"gross_pnl\"]),\n",
    "                                #float(data[symbol][\"fee\"]),\n",
    "                                #float(data[symbol][\"net_pnl\"]),\n",
    "                            )\n",
    "                          )\n",
    "\n",
    "        if data[symbol][\"entry_price\"] != None:\n",
    "            cursor.execute(\"INSERT OR REPLACE INTO data_{} (ticker_id, date, close, pred, induced_high, induced_low, position, entry_price) VALUES (?,?,?,?,?,?,?,?)\".format(data[symbol][\"ticker\"]),\n",
    "                            (\n",
    "                                int(ticker_id),\n",
    "                                str(data[symbol][\"date\"]),\n",
    "                                float(data[symbol][\"close\"]),\n",
    "                                float(data[symbol][\"pred\"]),\n",
    "                                float(data[symbol][\"induced_high\"]),\n",
    "                                float(data[symbol][\"induced_low\"]),\n",
    "                                float(data[symbol][\"position\"]),\n",
    "                                float(data[symbol][\"entry_price\"]),\n",
    "                                #float(data[symbol][\"exit_price\"]),\n",
    "                                #int(data[symbol][\"duration\"]),\n",
    "                                #float(data[symbol][\"gross_pnl\"]),\n",
    "                                #float(data[symbol][\"fee\"]),\n",
    "                                #float(data[symbol][\"net_pnl\"]),\n",
    "                            )\n",
    "                          )\n",
    "\n",
    "        if data[symbol][\"exit_price\"] != None:\n",
    "            cursor.execute(\"INSERT OR REPLACE INTO data_{} (ticker_id, date, close, pred, induced_high, induced_low, position, exit_price, duration, gross_pnl, fee, net_pnl) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\".format(data[symbol][\"ticker\"]),\n",
    "                            (\n",
    "                                int(ticker_id),\n",
    "                                str(data[symbol][\"date\"]),\n",
    "                                float(data[symbol][\"close\"]),\n",
    "                                float(data[symbol][\"pred\"]),\n",
    "                                float(data[symbol][\"induced_high\"]),\n",
    "                                float(data[symbol][\"induced_low\"]),\n",
    "                                float(data[symbol][\"position\"]),\n",
    "                                #float(data[symbol][\"entry_price\"]),\n",
    "                                float(data[symbol][\"exit_price\"]),\n",
    "                                int(data[symbol][\"duration\"]),\n",
    "                                float(data[symbol][\"gross_pnl\"]),\n",
    "                                float(data[symbol][\"fee\"]),\n",
    "                                float(data[symbol][\"net_pnl\"]),\n",
    "                            )\n",
    "                          )\n",
    "\n",
    "        self.commit_close_db()\n",
    "\n",
    "    def get_prev_position_db(self, symbol):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('SELECT position FROM data_{} ORDER BY date DESC LIMIT 1'.format(symbol))\n",
    "        position = cursor.fetchone()\n",
    "\n",
    "        if not position:\n",
    "            return 0\n",
    "        else:\n",
    "            return position[0]\n",
    "\n",
    "    def get_date_of_last_entry_db(self, symbol, today=pd.Timestamp.today().normalize(), timezone='America/New_York'):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('SELECT date FROM data_{} WHERE entry_price IS NOT NULL ORDER BY date DESC LIMIT 1'.format(symbol))\n",
    "        last_entry_date = cursor.fetchone()\n",
    "\n",
    "        if not last_entry_date:\n",
    "            return today - pd.Timedelta(days=1)\n",
    "        else:\n",
    "            last_entry_date = pd.Timestamp(f'{last_entry_date[0]}')\n",
    "            last_entry_date = last_entry_date.tz_localize(timezone)\n",
    "            \n",
    "            return last_entry_date\n",
    "\n",
    "    def get_price_of_last_entry_db(self, symbol):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('SELECT entry_price FROM data_{} WHERE entry_price IS NOT NULL ORDER BY date DESC LIMIT 1'.format(symbol))\n",
    "        last_entry_price = cursor.fetchone()\n",
    "\n",
    "        if not last_entry_price:\n",
    "            return 0.\n",
    "        else:\n",
    "            return last_entry_price[0]\n",
    "\n",
    "    def check_position_change_db(self, symbol):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        cursor.execute('SELECT position FROM data_{} ORDER BY date DESC LIMIT 2'.format(symbol))\n",
    "        position_new = cursor.fetchone()\n",
    "        position_new = position_new[0]\n",
    "        position_old = cursor.fetchone()\n",
    "\n",
    "        if not position_old:\n",
    "            position_old = 0\n",
    "        else:\n",
    "            position_old = position_old[0]\n",
    "        \n",
    "        if position_new != position_old:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def export_to_excel_db(self, file_path=\"tickers-nasdaq.txt\"):\n",
    "        connection, cursor = self.connect_db()\n",
    "\n",
    "        output_directory = 'bcc-bot-output'\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        tickerSymbols = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                tickerSymbols.append(line.strip())\n",
    "\n",
    "        for symbol in tickerSymbols:\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM data_{symbol}\", connection)\n",
    "            df.to_excel(f'{output_directory}/data_{symbol}.xlsx', index=False)\n",
    "            \n",
    "        connection.close()\n",
    "    \n",
    "    def connect_db(self):\n",
    "        import sqlite3\n",
    "        self.connection = sqlite3.connect(self.db_name)\n",
    "        self.cursor = self.connection.cursor()\n",
    "\n",
    "        return self.connection, self.cursor\n",
    "\n",
    "    def commit_close_db(self):\n",
    "        self.connection.commit()\n",
    "        self.connection.close()\n",
    "\n",
    "    ## Creating sequences\n",
    "    @staticmethod\n",
    "    def create_dataset(dataset, time_step=1, output_step=1):   \n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-output_step):\n",
    "            a = dataset[i:(i+time_step), 0]\n",
    "            b = dataset[(i+time_step):(i+time_step)+output_step, 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(b)\n",
    "    \n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    ## Is working day?\n",
    "    @staticmethod\n",
    "    def is_working_day(date, country='US'):\n",
    "        import holidays\n",
    "        \n",
    "        are_holidays = holidays.CountryHoliday(country)\n",
    "        return date.weekday() < 5 and date not in are_holidays\n",
    "\n",
    "    ## Initialized trained model\n",
    "    @staticmethod\n",
    "    def initialize_model(units = 1024,\n",
    "                         input_period = 46,\n",
    "                         num_features = 1,\n",
    "                         output_step = 7,\n",
    "                         best_epoch_backup = 94,\n",
    "                         model_weights_path = 'model_weights_2'\n",
    "                        ):\n",
    "        # Build LSTM model\n",
    "        model = Sequential([\n",
    "            LSTM(units=units, input_shape=(input_period, num_features)),\n",
    "            Dense(output_step)\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "        # Load the weights of the model at the chosen epoch\n",
    "        model.load_weights(f'{model_weights_path}/model_weights_epoch_{best_epoch_backup:02d}.h5')\n",
    "        print('Backup: Weigths for the best epoch has been loaded.')\n",
    "    \n",
    "        return model\n",
    "\n",
    "    ## Process given ticker\n",
    "    def process_ticker(self,\n",
    "                       tickerSymbol,\n",
    "                       start = pd.Timestamp.today().normalize() - pd.Timedelta(days=100),\n",
    "                       end = pd.Timestamp.today().normalize(),\n",
    "                       interval = '1d',\n",
    "                       #file_path = \"tickers-nasdaq.txt\",\n",
    "                       trend_period = 14,\n",
    "                       input_period = 46,\n",
    "                       period = 60,\n",
    "                       model = initialize_model(),\n",
    "                       timezone = 'America/New_York',\n",
    "                       verbose = False\n",
    "                      ):\n",
    "        \n",
    "        if type(start) != pd.Timestamp:\n",
    "            start = pd.Timestamp(f'{start} 00:00:00')\n",
    "            start = start.tz_localize(timezone)\n",
    "    \n",
    "        if end is None:\n",
    "            pass\n",
    "        else:\n",
    "            if type(end) != pd.Timestamp:\n",
    "                end = pd.Timestamp(f'{end} 00:00:00')\n",
    "                end = end.tz_localize(timezone)\n",
    "    \n",
    "        tickerData = yf.Ticker(tickerSymbol)\n",
    "        df = tickerData.history(start=start, end=end, interval=interval, auto_adjust=False)\n",
    "        df = df.tail(period)\n",
    "    \n",
    "        # Select only the necessary columns\n",
    "        df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "        df.rename(columns={'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)\n",
    "        df.rename_axis('date', inplace=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Raw data for {tickerSymbol} has been loaded\")\n",
    "    \n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        \n",
    "        X = df[['close']].to_numpy()\n",
    "        decomposition = seasonal_decompose(X, model='additive', period=trend_period)\n",
    "        trend = decomposition.trend\n",
    "        trend = trend[~np.isnan(trend)]\n",
    "    \n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "        scaler = MinMaxScaler()\n",
    "        trend_scaled = scaler.fit_transform(trend.reshape(-1,1))\n",
    "    \n",
    "        pred = model.predict(trend_scaled.reshape(trend_scaled.shape[1], input_period, 1), verbose=0)\n",
    "        pred = scaler.inverse_transform(pred)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Predictions for {tickerSymbol} has been generated\")\n",
    "    \n",
    "        noise_high = df[['high']].to_numpy()\n",
    "        noise_low = df[['low']].to_numpy()\n",
    "        std_dev_high = np.std(noise_high)\n",
    "        std_dev_low = np.std(noise_low)\n",
    "        std_dev_noise = np.maximum(std_dev_high, std_dev_low)\n",
    "    \n",
    "        induced_high = pred[0] + std_dev_noise\n",
    "        induced_low = pred[0] - std_dev_noise\n",
    "    \n",
    "        return {\n",
    "            'ticker': tickerSymbol,\n",
    "            'date': end.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'close': df['close'].iloc[-1],\n",
    "            'pred': pred[0][0],\n",
    "            'induced_high': induced_high[0],\n",
    "            'induced_low': induced_low[0],\n",
    "            'position': None,\n",
    "            'entry_price': None,\n",
    "            'exit_price': None,\n",
    "            'duration': None,\n",
    "            'gross_pnl': None,\n",
    "            'fee': None,\n",
    "            'net_pnl': None\n",
    "        }\n",
    "\n",
    "    def process_all_tickers(self,\n",
    "                            file_path = \"tickers-nasdaq.txt\",\n",
    "                            today = pd.Timestamp.today().normalize(),\n",
    "                            timezone = 'America/New_York'\n",
    "                           ):\n",
    "        if type(today) != pd.Timestamp:\n",
    "            today = pd.Timestamp(f'{today} 00:00:00')\n",
    "            today = today.tz_localize(timezone)\n",
    "            \n",
    "        tickerSymbols = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                tickerSymbols.append(line.strip())\n",
    "\n",
    "        from tqdm import tqdm\n",
    "        for symbol in tqdm(tickerSymbols):\n",
    "            self.DATA[symbol] = self.process_ticker(symbol, start=today - pd.Timedelta(days=100), end=today)\n",
    "            self.DATA[symbol]['position'] = (self.process_ticker(symbol, start=today - pd.Timedelta(days=100), end=today - pd.Timedelta(days=1))['induced_low'] < self.DATA[symbol]['induced_low']).astype(int)\n",
    "\n",
    "            if self.DATA[symbol]['position'] == 1 and self.get_prev_position_db(symbol) == 0:\n",
    "                self.DATA[symbol]['entry_price'] = self.DATA[symbol]['close']\n",
    "\n",
    "            if self.DATA[symbol]['position'] == 0 and self.get_prev_position_db(symbol) == 1:\n",
    "                self.DATA[symbol]['exit_price'] = self.DATA[symbol]['close']\n",
    "                self.DATA[symbol]['duration'] = (today - self.get_date_of_last_entry_db(symbol, today=today)).days\n",
    "                self.DATA[symbol]['gross_pnl'] = (self.DATA[symbol]['exit_price'] - self.get_price_of_last_entry_db(symbol)) / self.get_price_of_last_entry_db(symbol)\n",
    "                self.DATA[symbol]['fee'] = self.DATA[symbol]['gross_pnl'] * 0.002\n",
    "                self.DATA[symbol]['net_pnl'] = self.DATA[symbol]['gross_pnl'] - self.DATA[symbol]['fee']\n",
    "\n",
    "            self.insert_data_db(symbol, self.DATA)\n",
    "\n",
    "        # check position changes\n",
    "        message = []\n",
    "        for symbol in tickerSymbols:\n",
    "            if self.check_position_change_db(symbol):\n",
    "                if self.DATA[symbol]['position'] == 1:\n",
    "                    message.append(f\"Open position for {symbol} with LONG\")\n",
    "                elif self.DATA[symbol]['position'] == 0:\n",
    "                    message.append(f\"Close position {symbol} with SHORT\")\n",
    "            else:\n",
    "                if self.DATA[symbol]['position'] == 1:\n",
    "                    message.append(f\"Hold position for {symbol}\")\n",
    "                elif self.DATA[symbol]['position'] == 0:\n",
    "                    message.append(f\"No buy signal for {symbol}\")\n",
    "        if not message:\n",
    "            message.append(\"No news\")\n",
    "\n",
    "        #self.send_mail(message, today=today)\n",
    "            \n",
    "        return self.DATA\n",
    "\n",
    "    def send_mail(self, text: str, today=pd.Timestamp.today().normalize()):\n",
    "        import smtplib\n",
    "        from email.mime.text import MIMEText\n",
    "        from email.mime.multipart import MIMEMultipart\n",
    "        \n",
    "        # Email credentials\n",
    "        sender_email = \"emailadress\"\n",
    "        sender_password = \"password\"\n",
    "        recipient_email = [\"emailadress\", \"emailadress\"]\n",
    "        \n",
    "        # Create a message\n",
    "        message = MIMEMultipart()\n",
    "        message[\"From\"] = sender_email\n",
    "        message[\"To\"] = \", \".join(recipient_email)\n",
    "        message[\"Subject\"] = \"BCC BOT - Daily Notification Mail\"\n",
    "        \n",
    "        # Add body to the email\n",
    "        body = f\"TODAY'S REPORT for {today}\" + \"\\n\"\n",
    "        for t in text:\n",
    "            body += t + \"\\n\"\n",
    "        message.attach(MIMEText(body, \"plain\"))\n",
    "        \n",
    "        # Connect to the SMTP server\n",
    "        with smtplib.SMTP(\"smtp.office365.com\", 587) as server:\n",
    "            server.starttls()  # Start TLS encryption\n",
    "            server.login(sender_email, sender_password)  # Login to the SMTP server\n",
    "            text = message.as_string()  # Convert the message to a string\n",
    "            server.sendmail(sender_email, recipient_email, text)  # Send the email\n",
    "            print(\"Email sent successfully!\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fbe466-cb3e-4b28-a72c-a63f6495d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = BCC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30275efb-b161-4dff-b963-18b2165ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "_date = pd.Timestamp(\"2023-12-04\")\n",
    "_date = _date.tz_localize('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722f9de8-0cf8-4a42-8a9f-592a6e9d0f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:57<00:00,  1.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:56<00:00,  1.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:57<00:00,  1.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:59<00:00,  1.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:59<00:00,  1.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:57<00:00,  1.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:57<00:00,  1.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:57<00:00,  1.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:58<00:00,  1.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:01<00:00,  1.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:59<00:00,  1.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:59<00:00,  1.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:00<00:00,  1.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:59<00:00,  1.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:00<00:00,  1.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:00<00:00,  1.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:00<00:00,  1.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:04<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:01<00:00,  1.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:00<00:00,  1.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:02<00:00,  1.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:01<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for delta in range(50):\n",
    "    if BCC.is_working_day(_date + pd.Timedelta(days=delta)):\n",
    "        day = bot.process_all_tickers(today=_date + pd.Timedelta(days=delta))\n",
    "        res.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab6b8da-d6c2-4d7a-99b3-7db41cf98a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.export_to_excel_db()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
