{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701c3de0-2caa-47a0-b003-de7dbb4b7c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported and copied.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/^NDX_raw_data.csv')\n",
    "data.rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)\n",
    "\n",
    "data_backup = data.iloc[3524:]\n",
    "\n",
    "data = data.iloc[:3524]\n",
    "data_copy = data.copy()\n",
    "\n",
    "print('Data imported and copied.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f10fd6-eb38-4d8e-8273-cc291d0e292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Creating sequences\n",
    "def create_dataset(dataset, time_step=1, output_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-output_step):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        b = dataset[(i+time_step):(i+time_step)+output_step, 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(b)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "period = 60\n",
    "trend_period = 14\n",
    "rsi_period = 14\n",
    "num_features = 3\n",
    "input_period = 46\n",
    "output_step = 7\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46088f64-d1b4-41f6-ba71-5b4eb357c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(data[['close']].to_numpy(), time_step=period, output_step=output_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b91c775-12cb-4200-998e-a8be3d9af59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = np.array([np.concatenate((X[i], y[i]), axis=0) for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8adc375-912d-4729-bafc-c86324365ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decompositions = np.array([seasonal_decompose(data_input[i], model='additive', period=14) for i in range(data_input.shape[0])])\n",
    "trends = np.array([decompositions[i].trend for i in range(decompositions.shape[0])])\n",
    "seasons = np.array([decompositions[i].seasonal for i in range(decompositions.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fb7279-5ac5-424c-b683-b714a2ccf0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from talib import RSI\n",
    "\n",
    "rsi = np.array([ RSI(data_input[i]) for i in range(data_input.shape[0]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33a600d-a762-46a3-821c-b8fa1424cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_dropna = list()\n",
    "seasons_cropped = list()\n",
    "rsi_dropna = list()\n",
    "\n",
    "for trend in trends:\n",
    "    trends_dropna.append(trend[~np.isnan(trend)])\n",
    "\n",
    "for season in seasons:\n",
    "    #seasons_cropped.append(season[int(trend_period/2):-int(trend_period/2)])\n",
    "    seasons_cropped.append(season[trend_period:])\n",
    "\n",
    "for r in rsi:\n",
    "    #rsi_dropna.append(r[-53:])\n",
    "    rsi_dropna.append(r[rsi_period:])\n",
    "\n",
    "trends_dropna = np.array(trends_dropna)\n",
    "seasons_cropped = np.array(seasons_cropped)\n",
    "rsi_dropna = np.array(rsi_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e45886-adef-4cc0-9ec8-57d0edc62ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = list(MinMaxScaler() for i in range(trends_dropna.shape[0]))\n",
    "trends_scaled = list()\n",
    "\n",
    "scaler_seasonal = list(MinMaxScaler() for i in range(seasons_cropped.shape[0]))\n",
    "seasons_scaled = list()\n",
    "\n",
    "scaler_rsi = list(MinMaxScaler() for i in range(rsi_dropna.shape[0]))\n",
    "rsi_scaled = list()\n",
    "\n",
    "for i in range(trends_dropna.shape[0]):\n",
    "    trends_scaled.append(scaler[i].fit_transform(trends_dropna[i].reshape(-1,1)))\n",
    "\n",
    "for i in range(seasons_cropped.shape[0]):\n",
    "    seasons_scaled.append(scaler_seasonal[i].fit_transform(seasons_cropped[i].reshape(-1,1)))\n",
    "\n",
    "for i in range(rsi_dropna.shape[0]):\n",
    "    rsi_scaled.append(scaler_rsi[i].fit_transform(rsi_dropna[i].reshape(-1,1)))\n",
    "\n",
    "trends_scaled = np.array(trends_scaled)\n",
    "seasons_scaled = np.array(seasons_scaled)\n",
    "rsi_scaled = np.array(rsi_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c21df1-3b1a-45b2-82b0-0c365a1d3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = list()\n",
    "y_input = list()\n",
    "\n",
    "for trend, season, rsi in zip(trends_scaled, seasons_scaled, rsi_scaled):\n",
    "    X_input.append(np.hstack((trend[:trend.shape[0]-7], season[:season.shape[0]-7], rsi[:rsi.shape[0]-7])))\n",
    "    y_input.append(trend[trend.shape[0]-7:])\n",
    "\n",
    "X_input = np.array(X_input)\n",
    "y_input = np.array(y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c274580-6a1b-471e-8462-6b330c9ee30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3457, 46, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d98ec-564d-4b3d-8eb8-a22e33de7e43",
   "metadata": {},
   "source": [
    "# **Main Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d588fb-8a3d-45ed-93bd-10ba0eea3014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:31:48.663547: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 20:31:49.331184: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 20:31:49.331335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 20:31:49.404940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 20:31:49.551623: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 20:31:52.119895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Conv1D, AveragePooling1D, Flatten, Reshape, SimpleRNN, GRU, MaxPooling1D, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import Zeros\n",
    "\n",
    "inputs = Input(shape=(input_period, num_features))\n",
    "\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(filters=512, kernel_size=1, activation='relu'),\n",
    "    Conv1D(filters=512, kernel_size=1, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dense(units=128),\n",
    "    Flatten()\n",
    "    #Dense(units=output_step),\n",
    "    #Reshape((output_step,1))\n",
    "])\n",
    "\n",
    "model_bilstm = Sequential([\n",
    "    Bidirectional(LSTM(units=512, return_sequences=True, activation='tanh', recurrent_activation='sigmoid')),\n",
    "    Dropout(0.2),\n",
    "    Flatten()\n",
    "    #Dense(units=output_step),\n",
    "    #Reshape((output_step,1))\n",
    "])\n",
    "\n",
    "model_bigru = Sequential([\n",
    "    Bidirectional(GRU(units=512, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "model_multilayer_lstm = Sequential([\n",
    "    LSTM(units=512, return_sequences=True, activation='tanh', recurrent_activation='sigmoid'),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units=512, return_sequences=True, activation='tanh', recurrent_activation='sigmoid'),\n",
    "    Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e8ca82-fd47-49fd-996f-7a7e3386e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cnn = model_cnn(inputs)\n",
    "output_bilstm = model_bilstm(inputs)\n",
    "output_bigru = model_bigru(inputs)\n",
    "output_multilayer_lstm = model_multilayer_lstm(inputs)\n",
    "\n",
    "concatenated_outputs = concatenate([output_cnn, output_bilstm, output_bigru, output_multilayer_lstm])\n",
    "\n",
    "main_model = Sequential([\n",
    "    Input(shape=(concatenated_outputs.shape[1],)),\n",
    "    Dense(units=output_step),\n",
    "    Reshape((output_step,1))\n",
    "])\n",
    "\n",
    "final_output = main_model(concatenated_outputs)\n",
    "\n",
    "functional_pipeline = Model(inputs=inputs, outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a54ca1-628d-4b8c-8f81-04e7e7842b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3457, 46, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53914bb-9b87-4635-b0e8-5a7324ef1489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:32:14.691662: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 12058624 exceeds 10% of free system memory.\n",
      "2024-05-27 20:32:14.717667: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 12058624 exceeds 10% of free system memory.\n",
      "2024-05-27 20:32:15.539601: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 12058624 exceeds 10% of free system memory.\n",
      "2024-05-27 20:32:15.564975: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 12058624 exceeds 10% of free system memory.\n",
      "2024-05-27 20:32:15.751098: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30638080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 215s 5s/step - loss: 0.2352 - accuracy: 0.0762 - val_loss: 0.0226 - val_accuracy: 0.0840\n",
      "Epoch 2/150\n",
      " 1/44 [..............................] - ETA: 3:15 - loss: 0.0252 - accuracy: 0.0848"
     ]
    }
   ],
   "source": [
    "# Compile the pipeline model\n",
    "functional_pipeline.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='model_weights_6_3_main_1024/model_weights_epoch_{epoch:02d}.h5', \n",
    "                            save_best_only=True, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the pipeline model\n",
    "history = functional_pipeline.fit(X_input, y_input, epochs=150, batch_size=64, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca858597-3889-429b-b445-59c3990c98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the epoch\n",
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "best_epoch = best_epoch+1\n",
    "print(f'best result is for epoch number {best_epoch}')\n",
    "\n",
    "# Load the weights of the model at the chosen epoch\n",
    "functional_pipeline.load_weights(f'model_weights_6_3_main_1024/model_weights_epoch_{best_epoch:02d}.h5')\n",
    "print('Weigths for the best epoch has been loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a593e98-956c-4f0b-884d-b93a147834d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_backup = 35\n",
    "\n",
    "# Load the weights of the model at the chosen epoch\n",
    "functional_pipeline.load_weights(f'model_weights_6_3_main_1024/model_weights_epoch_{best_epoch_backup:02d}.h5')\n",
    "print('Backup: Weigths for the best epoch has been loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5023b4-4d7b-49a3-8e31-5359c7880707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064dfd92-f177-4c05-9a6e-e286e709d393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554765d9-939d-4a90-b8bc-43b843ee15b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a291141-5936-4e0a-8bed-c1f2e8c52aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e90399-202b-4847-9bfa-77356c55f3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
