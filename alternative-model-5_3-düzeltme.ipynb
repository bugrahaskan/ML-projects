{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f4ec65-887e-4ea2-bc74-d5b28d1d0cbd",
   "metadata": {},
   "source": [
    "#### model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09729998-f728-4042-9f07-314a73983dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/^NDX_raw_data.csv')\n",
    "data.rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)\n",
    "\n",
    "data_backup = data.iloc[3524:]\n",
    "data = data.iloc[:3524]\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "period = 14\n",
    "nb_last_bars = 10\n",
    "\n",
    "decomposition_high = seasonal_decompose(data['high'], model='additive', period=period)\n",
    "trend_high = decomposition_high.trend\n",
    "\n",
    "decomposition_low = seasonal_decompose(data['low'], model='additive', period=period)\n",
    "trend_low = decomposition_low.trend\n",
    "\n",
    "data['trend_high'] = trend_high\n",
    "data['trend_low'] = trend_low\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(1,nb_last_bars+1):\n",
    "    data[f'trend_h+{i}'] = data['trend_high'].shift(i)\n",
    "for i in range(1,nb_last_bars+1):\n",
    "    data[f'trend_l+{i}'] = data['trend_low'].shift(i)\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "#inputs_high = data.iloc[:, [8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]\n",
    "inputs_high = data.iloc[:, [8,9,10,11,12,13,14,15,16,17]]\n",
    "target_high = data.iloc[:, [6]]\n",
    "\n",
    "#inputs_low = data.iloc[:, [28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47]]\n",
    "inputs_low = data.iloc[:, [18,19,20,21,22,23,24,25,26,27]]\n",
    "target_low = data.iloc[:, [7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b74025-b2d8-42e8-8f74-59beea6c5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(inputs_high, target_high, test_size=0.2, random_state=1, shuffle=False)\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(inputs_low, target_low, test_size=0.2, random_state=1, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler_h = MinMaxScaler()\n",
    "scaler_h.fit(X_train_h)\n",
    "scaler_target_h = MinMaxScaler()\n",
    "scaler_target_h.fit(y_train_h)\n",
    "\n",
    "scaler_l = MinMaxScaler()\n",
    "scaler_l.fit(X_train_l)\n",
    "scaler_target_l = MinMaxScaler()\n",
    "scaler_target_l.fit(y_train_l)\n",
    "\n",
    "X_train_h_scaled = scaler_h.transform(X_train_h)\n",
    "X_test_h_scaled = scaler_h.transform(X_test_h)\n",
    "y_train_h_scaled = scaler_target_h.transform(y_train_h)\n",
    "y_test_h_scaled = scaler_target_h.transform(y_test_h)\n",
    "\n",
    "X_train_l_scaled = scaler_l.transform(X_train_l)\n",
    "X_test_l_scaled = scaler_l.transform(X_test_l)\n",
    "y_train_l_scaled = scaler_target_l.transform(y_train_l)\n",
    "y_test_l_scaled = scaler_target_l.transform(y_test_l)\n",
    "\n",
    "random_tree_high_20 = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "random_tree_high_20.fit(X_train_h_scaled, y_train_h_scaled)\n",
    "\n",
    "random_tree_low_20 = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "random_tree_low_20.fit(X_train_l_scaled, y_train_l_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5f3e3-8216-4978-8f19-142bbdf02e3a",
   "metadata": {},
   "source": [
    "#### data reading for all stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7ec77e-1a40-4c95-9168-59fc8b618348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "directory = 'data'\n",
    "\n",
    "df_data = dict()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    symbol_pattern = re.match(r'([^_]+)_', file)\n",
    "    symbol = symbol_pattern.group(1)\n",
    "    df_data[symbol] = pd.read_csv(os.path.join(directory, file))\n",
    "    df_data[symbol].rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7279d71d-8659-4a3d-99da-aebd802722d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing for AAPL\n",
      "processing for AXP\n",
      "processing for AMZN\n",
      "processing for AMAT\n",
      "processing for ABNB\n",
      "processing for AVGO\n",
      "processing for ABT\n",
      "processing for ADI\n",
      "processing for AMD\n",
      "processing for ADP\n",
      "processing for AMGN\n",
      "processing for ^NDX\n",
      "processing for ABBV\n",
      "processing for ACN\n",
      "processing for ADBE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "period = 14\n",
    "nb_last_bars = 10\n",
    "\n",
    "for symbol in df_data:\n",
    "    print(f'processing for {symbol}')\n",
    "    \n",
    "    # create columns with value 0\n",
    "    for i in range(0,nb_last_bars+1):\n",
    "        df_data[symbol][f'trend_h+{i}'] = 0.\n",
    "    for i in range(0,nb_last_bars+1):\n",
    "        df_data[symbol][f'trend_l+{i}'] = 0.\n",
    "    \n",
    "    for i in range(period*2, df_data[symbol].shape[0]):\n",
    "        # decompose in trend_high\n",
    "        decomposition_high_backup = seasonal_decompose(df_data[symbol]['high'].iloc[i-(period*2):i+1], model='additive', period=period)\n",
    "        trend_high_backup = decomposition_high_backup.trend\n",
    "    \n",
    "        trend_high_backup.dropna(axis=0, inplace=True)\n",
    "    \n",
    "        for j in range(0,nb_last_bars+1):\n",
    "            df_data[symbol].loc[i, f'trend_h+{j}'] = trend_high_backup.iloc[-1-j]\n",
    "    \n",
    "        # decompose in trend low\n",
    "        decomposition_low_backup = seasonal_decompose(df_data[symbol]['low'].iloc[i-(period*2):i+1], model='additive', period=period)\n",
    "        trend_low_backup = decomposition_low_backup.trend\n",
    "    \n",
    "        trend_low_backup.dropna(axis=0, inplace=True)\n",
    "    \n",
    "        for j in range(0,nb_last_bars+1):\n",
    "            df_data[symbol].loc[i, f'trend_l+{j}'] = trend_low_backup.iloc[-1-j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af75886d-dc3d-454a-9f24-d11156392435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in df_data:\n",
    "    # drop the first rows of NaN trends\n",
    "    df_data[symbol] = df_data[symbol].iloc[period*2:]\n",
    "    df_data[symbol].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9898624-fea2-4d98-9239-152ed73439de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5005, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['AAPL'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b13c20-9c88-4d41-9ebb-ca963530a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 AAPL\n",
      "2 AXP\n",
      "3 AMZN\n",
      "4 AMAT\n",
      "5 ABNB\n",
      "6 AVGO\n",
      "7 ABT\n",
      "8 ADI\n",
      "9 AMD\n",
      "10 ADP\n",
      "11 AMGN\n",
      "12 ^NDX\n",
      "13 ABBV\n",
      "14 ACN\n",
      "15 ADBE\n"
     ]
    }
   ],
   "source": [
    "df_pred = dict()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for symbol in df_data:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    #inputs_high_backup = df_data[symbol].iloc[:, [8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]]\n",
    "    inputs_high_backup = df_data[symbol].iloc[:, [8,9,10,11,12,13,14,15,16,17]]\n",
    "    #inputs_low_backup = df_data[symbol].iloc[:, [29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48]]\n",
    "    inputs_low_backup = df_data[symbol].iloc[:, [19,20,21,22,23,24,25,26,27,28]]\n",
    "\n",
    "    print(count, symbol)\n",
    "    \n",
    "    scaler_input = MinMaxScaler()\n",
    "    data_backup_h_scaled = scaler_input.fit_transform(inputs_high_backup)\n",
    "    scaler_target = MinMaxScaler()\n",
    "    target_backup_h_scaled = scaler_target.fit_transform(df_data[symbol][['trend_h+0']])\n",
    "\n",
    "    y_pred_h_backup = random_tree_high_20.predict(data_backup_h_scaled)\n",
    "    y_pred_h_backup = y_pred_h_backup.reshape(-1,1)\n",
    "    y_pred_h_backup = scaler_target.inverse_transform(y_pred_h_backup)\n",
    "\n",
    "    scaler_input = MinMaxScaler()\n",
    "    data_backup_l_scaled = scaler_input.fit_transform(inputs_low_backup)\n",
    "    scaler_target = MinMaxScaler()\n",
    "    target_backup_l_scaled = scaler_target.fit_transform(df_data[symbol][['trend_l+0']])\n",
    "\n",
    "    y_pred_l_backup = random_tree_low_20.predict(data_backup_l_scaled)\n",
    "    y_pred_l_backup = y_pred_l_backup.reshape(-1,1)\n",
    "    y_pred_l_backup = scaler_target.inverse_transform(y_pred_l_backup)\n",
    "\n",
    "    dict_pred = {'pred_h':y_pred_h_backup, 'pred_l':y_pred_l_backup}\n",
    "    df_pred[symbol] = dict_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e03db91-035e-4ca9-bc32-e4efa6ce2889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 METRICS FOR AAPL:\n",
      "score high: 1.5518134724016024\n",
      "score low: 1.5680704132702301\n",
      "- R2 METRICS FOR AAPL:\n",
      "r2 high: 0.9966014425456745\n",
      "r2 low: 0.9965663762845842\n",
      "2 METRICS FOR AXP:\n",
      "score high: 2.464856674096579\n",
      "score low: 2.4658695270333704\n",
      "- R2 METRICS FOR AXP:\n",
      "r2 high: 0.9900301044194336\n",
      "r2 low: 0.9894373794392579\n",
      "3 METRICS FOR AMZN:\n",
      "score high: 1.802451977615845\n",
      "score low: 1.8360055725924367\n",
      "- R2 METRICS FOR AMZN:\n",
      "r2 high: 0.9950156564326006\n",
      "r2 low: 0.9948580329461061\n",
      "4 METRICS FOR AMAT:\n",
      "score high: 1.700329221406803\n",
      "score low: 1.72658359333443\n",
      "- R2 METRICS FOR AMAT:\n",
      "r2 high: 0.9929232484841742\n",
      "r2 low: 0.9925164346700281\n",
      "5 METRICS FOR ABNB:\n",
      "score high: 8.943012584551475\n",
      "score low: 8.718621283026769\n",
      "- R2 METRICS FOR ABNB:\n",
      "r2 high: 0.8457012025838135\n",
      "r2 low: 0.8364587621722419\n",
      "6 METRICS FOR AVGO:\n",
      "score high: 10.911998831382878\n",
      "score low: 10.485620388755592\n",
      "- R2 METRICS FOR AVGO:\n",
      "r2 high: 0.9906567017003385\n",
      "r2 low: 0.99143957099244\n",
      "7 METRICS FOR ABT:\n",
      "score high: 1.2290396795842193\n",
      "score low: 1.2466638263591867\n",
      "- R2 METRICS FOR ABT:\n",
      "r2 high: 0.9960855160785514\n",
      "r2 low: 0.9958794512315338\n",
      "8 METRICS FOR ADI:\n",
      "score high: 2.201750773212388\n",
      "score low: 2.257475285870157\n",
      "- R2 METRICS FOR ADI:\n",
      "r2 high: 0.994791869444656\n",
      "r2 low: 0.994330525593273\n",
      "9 METRICS FOR AMD:\n",
      "score high: 1.8059217780478354\n",
      "score low: 1.737139298851089\n",
      "- R2 METRICS FOR AMD:\n",
      "r2 high: 0.9883492747987745\n",
      "r2 low: 0.9887386532470944\n",
      "10 METRICS FOR ADP:\n",
      "score high: 2.2858762630939102\n",
      "score low: 2.3373336376413882\n",
      "- R2 METRICS FOR ADP:\n",
      "r2 high: 0.9957422904945055\n",
      "r2 low: 0.9953774908328654\n",
      "11 METRICS FOR AMGN:\n",
      "score high: 3.84710664739022\n",
      "score low: 3.835176702244686\n",
      "- R2 METRICS FOR AMGN:\n",
      "r2 high: 0.9936637976098063\n",
      "r2 low: 0.9935383403479325\n",
      "12 METRICS FOR ^NDX:\n",
      "score high: 125.31185323959123\n",
      "score low: 131.95126917115914\n",
      "- R2 METRICS FOR ^NDX:\n",
      "r2 high: 0.9969766156295453\n",
      "r2 low: 0.9966715446023658\n",
      "13 METRICS FOR ABBV:\n",
      "score high: 2.6889113317341167\n",
      "score low: 2.7069252681837783\n",
      "- R2 METRICS FOR ABBV:\n",
      "r2 high: 0.9874340895035697\n",
      "r2 low: 0.9869941202938057\n",
      "14 METRICS FOR ACN:\n",
      "score high: 3.3122146293227672\n",
      "score low: 3.4082009356535714\n",
      "- R2 METRICS FOR ACN:\n",
      "r2 high: 0.995940540054442\n",
      "r2 low: 0.9956383815491824\n",
      "15 METRICS FOR ADBE:\n",
      "score high: 6.177133030906037\n",
      "score low: 6.208815488067574\n",
      "- R2 METRICS FOR ADBE:\n",
      "r2 high: 0.9946058992761995\n",
      "r2 low: 0.9944693761116782\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for symbol in df_data:\n",
    "    count += 1\n",
    "\n",
    "    #df_data[symbol].reset_index(inplace=True)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error\n",
    "    \n",
    "    score_h = mean_absolute_error(df_data[symbol][['high']], df_pred[symbol]['pred_h'])\n",
    "    r2_h = r2_score(df_data[symbol][['high']], df_pred[symbol]['pred_h'])\n",
    "    df_data[symbol]['mae_h'] = score_h\n",
    "    \n",
    "    score_l = mean_absolute_error(df_data[symbol][['low']], df_pred[symbol]['pred_l'])\n",
    "    r2_l = r2_score(df_data[symbol][['low']], df_pred[symbol]['pred_l'])\n",
    "    df_data[symbol]['mae_l'] = score_l\n",
    "    \n",
    "    print(f'{count} METRICS FOR {symbol}:')\n",
    "    print(f'score high: {score_h}')\n",
    "    print(f'score low: {score_l}')\n",
    "    \n",
    "    print(f'- R2 METRICS FOR {symbol}:')\n",
    "    print(f'r2 high: {r2_h}')\n",
    "    print(f'r2 low: {r2_l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b57487-bb7c-44ac-9673-586fcab4c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done for AAPL\n",
      "2 done for AXP\n",
      "3 done for AMZN\n",
      "4 done for AMAT\n",
      "5 done for ABNB\n",
      "6 done for AVGO\n",
      "7 done for ABT\n",
      "8 done for ADI\n",
      "9 done for AMD\n",
      "10 done for ADP\n",
      "11 done for AMGN\n",
      "12 done for ^NDX\n",
      "13 done for ABBV\n",
      "14 done for ACN\n",
      "15 done for ADBE\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "remaining_columns = ('date','open','high','low','close','volume','trend_h+0','trend_l+0','mae_h','mae_l')\n",
    "\n",
    "for symbol in df_data:\n",
    "    count += 1\n",
    "\n",
    "    df_data[symbol] = df_data[symbol][list(remaining_columns)]\n",
    "\n",
    "    y_pred_h_series = pd.Series(df_pred[symbol]['pred_h'].reshape(1,-1)[0])\n",
    "    y_pred_l_series = pd.Series(df_pred[symbol]['pred_l'].reshape(1,-1)[0])\n",
    "    df_data[symbol]['pred_high'] = y_pred_h_series\n",
    "    df_data[symbol]['pred_low'] = y_pred_l_series\n",
    "    \n",
    "    df_data[symbol].to_excel(f'data_w_pred_m5_3/{symbol}_w_pred_m5_3.xlsx')\n",
    "    \n",
    "    print(f'{count} done for {symbol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330fd89-c572-4dcc-bcb1-2864d0f92e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2c058-fb8f-49c2-ad67-3c2d6e1e7409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fb086a-6c43-49c5-b849-67c737bb55fe",
   "metadata": {},
   "source": [
    "# model training for 1 stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2190eb0f-77f7-4ad3-9540-2e1b1c658751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/^NDX_raw_data.csv')\n",
    "data.rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)\n",
    "\n",
    "data_backup = data.iloc[3524:]\n",
    "data = data.iloc[:3524]\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "period = 14\n",
    "nb_last_bars = 10\n",
    "\n",
    "decomposition_high = seasonal_decompose(data['high'], model='additive', period=period)\n",
    "trend_high = decomposition_high.trend\n",
    "detrend_high = decomposition_high.seasonal + decomposition_high.resid\n",
    "\n",
    "decomposition_low = seasonal_decompose(data['low'], model='additive', period=period)\n",
    "trend_low = decomposition_low.trend\n",
    "detrend_low = decomposition_low.seasonal + decomposition_low.resid\n",
    "\n",
    "data['trend_high'] = trend_high\n",
    "data['trend_low'] = trend_low\n",
    "\n",
    "#data['detrend_high'] = detrend_high\n",
    "#data['detrend_low'] = detrend_low\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(1,nb_last_bars+1):\n",
    "    data[f'trend_h+{i}'] = data['trend_high'].shift(i)\n",
    "for i in range(1,nb_last_bars+1):\n",
    "    data[f'trend_l+{i}'] = data['trend_low'].shift(i)\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "inputs_high = data.iloc[:, [8,9,10,11,12,13,14,15,16,17]]\n",
    "target_high = data.iloc[:, [6]]\n",
    "\n",
    "inputs_low = data.iloc[:, [18,19,20,21,22,23,24,25,26,27]]\n",
    "target_low = data.iloc[:, [7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2637120f-0f09-4c18-8044-bd81f6770611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['date', 'open', 'high', 'low', 'close', 'volume', 'trend_high',\n",
       "        'trend_low', 'trend_h+1', 'trend_h+2', 'trend_h+3', 'trend_h+4',\n",
       "        'trend_h+5', 'trend_h+6', 'trend_h+7', 'trend_h+8', 'trend_h+9',\n",
       "        'trend_h+10', 'trend_l+1', 'trend_l+2', 'trend_l+3', 'trend_l+4',\n",
       "        'trend_l+5', 'trend_l+6', 'trend_l+7', 'trend_l+8', 'trend_l+9',\n",
       "        'trend_l+10'],\n",
       "       dtype='object'),\n",
       " (3500, 28))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d4c118-a1bc-4024-9bfc-1045636c2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(inputs_high, target_high, test_size=0.2, random_state=1, shuffle=False)\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(inputs_low, target_low, test_size=0.2, random_state=1, shuffle=False)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler_h = MinMaxScaler()\n",
    "scaler_h.fit(X_train_h)\n",
    "scaler_target_h = MinMaxScaler()\n",
    "scaler_target_h.fit(y_train_h)\n",
    "\n",
    "scaler_l = MinMaxScaler()\n",
    "scaler_l.fit(X_train_l)\n",
    "scaler_target_l = MinMaxScaler()\n",
    "scaler_target_l.fit(y_train_l)\n",
    "\n",
    "X_train_h_scaled = scaler_h.transform(X_train_h)\n",
    "X_test_h_scaled = scaler_h.transform(X_test_h)\n",
    "y_train_h_scaled = scaler_target_h.transform(y_train_h)\n",
    "y_test_h_scaled = scaler_target_h.transform(y_test_h)\n",
    "\n",
    "X_train_l_scaled = scaler_l.transform(X_train_l)\n",
    "X_test_l_scaled = scaler_l.transform(X_test_l)\n",
    "y_train_l_scaled = scaler_target_l.transform(y_train_l)\n",
    "y_test_l_scaled = scaler_target_l.transform(y_test_l)\n",
    "\n",
    "random_tree_high_10 = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "random_tree_high_10.fit(X_train_h_scaled, y_train_h_scaled)\n",
    "\n",
    "random_tree_low_10 = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "random_tree_low_10.fit(X_train_l_scaled, y_train_l_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be3d76-47d8-4662-b9fa-b91d017005ce",
   "metadata": {},
   "source": [
    "#### data reading for AAPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d422e4f-e517-40d5-94c4-3026dfddf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backup = pd.read_csv('data/AAPL_raw_data.csv')\n",
    "data_backup.rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ddc7ef1-f569-4f6a-8d72-9dc75e7a2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "period = 14\n",
    "nb_last_bars = 10\n",
    "\n",
    "# create columns with value 0\n",
    "for i in range(0,nb_last_bars+1):\n",
    "    data_backup[f'trend_h+{i}'] = 0.\n",
    "for i in range(0,nb_last_bars+1):\n",
    "    data_backup[f'trend_l+{i}'] = 0.\n",
    "\n",
    "for i in range(period*2, data_backup.shape[0]):\n",
    "    # decompose in trend_high\n",
    "    decomposition_high_backup = seasonal_decompose(data_backup['high'].iloc[i-(period*2):i+1], model='additive', period=period)\n",
    "    trend_high_backup = decomposition_high_backup.trend\n",
    "    detrend_high_backup = decomposition_high_backup.seasonal + decomposition_high_backup.resid\n",
    "\n",
    "    trend_high_backup.dropna(axis=0, inplace=True)\n",
    "\n",
    "    for j in range(0,nb_last_bars+1):\n",
    "        data_backup.loc[i, f'trend_h+{j}'] = trend_high_backup.iloc[-1-j]\n",
    "\n",
    "    # decompose in trend low\n",
    "    decomposition_low_backup = seasonal_decompose(data_backup['low'].iloc[i-(period*2):i+1], model='additive', period=period)\n",
    "    trend_low_backup = decomposition_low_backup.trend\n",
    "    detrend_low_backup = decomposition_low_backup.seasonal + decomposition_low_backup.resid\n",
    "\n",
    "    trend_low_backup.dropna(axis=0, inplace=True)\n",
    "\n",
    "    for j in range(0,nb_last_bars+1):\n",
    "        data_backup.loc[i, f'trend_l+{j}'] = trend_low_backup.iloc[-1-j]\n",
    "\n",
    "# drop the first rows of NaN trends\n",
    "data_backup = data_backup.iloc[period*2:]\n",
    "data_backup.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0be16eb-3287-4720-8440-1e02bf26a1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['index', 'date', 'open', 'high', 'low', 'close', 'volume', 'trend_h+0',\n",
       "        'trend_h+1', 'trend_h+2', 'trend_h+3', 'trend_h+4', 'trend_h+5',\n",
       "        'trend_h+6', 'trend_h+7', 'trend_h+8', 'trend_h+9', 'trend_h+10',\n",
       "        'trend_l+0', 'trend_l+1', 'trend_l+2', 'trend_l+3', 'trend_l+4',\n",
       "        'trend_l+5', 'trend_l+6', 'trend_l+7', 'trend_l+8', 'trend_l+9',\n",
       "        'trend_l+10'],\n",
       "       dtype='object'),\n",
       " (5005, 29))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_backup.columns, data_backup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b4f3e7-1af2-4222-983d-9e7a5b64a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = dict()\n",
    "\n",
    "inputs_high_backup = data_backup.iloc[:, [8,9,10,11,12,13,14,15,16,17]]\n",
    "inputs_low_backup = data_backup.iloc[:, [19,20,21,22,23,24,25,26,27,28]]\n",
    "\n",
    "scaler_input = MinMaxScaler()\n",
    "data_backup_h_scaled = scaler_input.fit_transform(inputs_high_backup)\n",
    "scaler_target = MinMaxScaler()\n",
    "target_backup_h_scaled = scaler_target.fit_transform(data_backup[['trend_h+0']])\n",
    "\n",
    "y_pred_h_backup = random_tree_high_10.predict(data_backup_h_scaled)\n",
    "y_pred_h_backup = y_pred_h_backup.reshape(-1,1)\n",
    "y_pred_h_backup = scaler_target.inverse_transform(y_pred_h_backup)\n",
    "\n",
    "scaler_input = MinMaxScaler()\n",
    "data_backup_l_scaled = scaler_input.fit_transform(inputs_low_backup)\n",
    "scaler_target = MinMaxScaler()\n",
    "target_backup_l_scaled = scaler_target.fit_transform(data_backup[['trend_l+0']])\n",
    "\n",
    "y_pred_l_backup = random_tree_low_10.predict(data_backup_l_scaled)\n",
    "y_pred_l_backup = y_pred_l_backup.reshape(-1,1)\n",
    "y_pred_l_backup = scaler_target.inverse_transform(y_pred_l_backup)\n",
    "\n",
    "df_pred = {'pred_h':y_pred_h_backup, 'pred_l':y_pred_l_backup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60fa9304-c772-480f-b867-a37c5a56fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS FOR NASDAQ INDEX:\n",
      "score high: 1.5518134724016024\n",
      "score low: 1.5680704132702301\n",
      "- R2 METRICS FOR NASDAQ INDEX:\n",
      "r2 high: 0.9966014425456745\n",
      "r2 low: 0.9965663762845842\n"
     ]
    }
   ],
   "source": [
    "data_backup.reset_index(inplace=True)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error\n",
    "\n",
    "score_h = mean_absolute_error(data_backup[['high']], df_pred['pred_h'])\n",
    "r2_h = r2_score(data_backup[['high']], df_pred['pred_h'])\n",
    "data_backup['mae_h'] = score_h\n",
    "\n",
    "score_l = mean_absolute_error(data_backup[['low']], df_pred['pred_l'])\n",
    "r2_l = r2_score(data_backup[['low']], df_pred['pred_l'])\n",
    "data_backup['mae_l'] = score_l\n",
    "\n",
    "print(f'METRICS FOR NASDAQ INDEX:')\n",
    "print(f'score high: {score_h}')\n",
    "print(f'score low: {score_l}')\n",
    "\n",
    "print(f'- R2 METRICS FOR NASDAQ INDEX:')\n",
    "print(f'r2 high: {r2_h}')\n",
    "print(f'r2 low: {r2_l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af6adba3-4dc4-4491-9dd0-ef9c1a54fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213683/1916406721.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_backup['pred_high'] = y_pred_h_series\n",
      "/tmp/ipykernel_213683/1916406721.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_backup['pred_low'] = y_pred_l_series\n"
     ]
    }
   ],
   "source": [
    "remaining_columns = ('date','open','high','low','close','volume','trend_h+0','trend_l+0','mae_h','mae_l')\n",
    "\n",
    "data_backup = data_backup[list(remaining_columns)]\n",
    "\n",
    "y_pred_h_series = pd.Series(df_pred['pred_h'].reshape(1,-1)[0])\n",
    "y_pred_l_series = pd.Series(df_pred['pred_l'].reshape(1,-1)[0])\n",
    "data_backup['pred_high'] = y_pred_h_series\n",
    "data_backup['pred_low'] = y_pred_l_series\n",
    "\n",
    "data_backup.to_excel(f'data_w_pred_m5_3/AAPL_w_pred_m5_3-10bar.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490fa6b-2e33-4ef9-aee5-f4c356641d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
