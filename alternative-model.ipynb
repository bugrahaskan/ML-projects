{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88350a6e-3b4b-44d9-9322-d37913990348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/^NDX_raw_data.csv')\n",
    "data.rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058d75bb-e8bf-4203-81cf-3f603c873e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:3524]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33924ec-a966-4b42-93eb-66516fa226ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3524 entries, 0 to 3523\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    3524 non-null   object \n",
      " 1   open    3524 non-null   float64\n",
      " 2   high    3524 non-null   float64\n",
      " 3   low     3524 non-null   float64\n",
      " 4   close   3524 non-null   float64\n",
      " 5   volume  3524 non-null   int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 165.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f3101-b8d0-4cea-be17-96b0f92d014d",
   "metadata": {},
   "source": [
    "### prepare models for close, high, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f800f1a9-d3d7-4bc9-bec7-aa3aee0499bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from talib import RSI\n",
    "data['rsi_14'] = RSI(data['close'], timeperiod=14)\n",
    "#data['rsi_14'] = data['rsi_14'].shift(1)\n",
    "\n",
    "from talib import MA, SMA, EMA, WMA\n",
    "data['ma_9'] = MA(data['close'], timeperiod=9)\n",
    "#data['ma_9'] = data['ma_9'].shift(1)\n",
    "data['sma_9'] = SMA(data['close'], timeperiod=9)\n",
    "#data['sma_9'] = data['sma_9'].shift(1)\n",
    "data['wma_9'] = WMA(data['close'], timeperiod=9)\n",
    "#data['wma_9'] = data['wma_9'].shift(1)\n",
    "\n",
    "from talib import MACD\n",
    "data['macd'], data['signal'], data['hist'] = MACD(data['close'])\n",
    "#data['macd'] = data['macd'].shift(1)\n",
    "#data['signal'] = data['signal'].shift(1)\n",
    "#data['hist'] = data['hist'].shift(1)\n",
    "\n",
    "from talib import ADX\n",
    "data['adx'] = ADX(data['high'], data['low'], data['close'])\n",
    "#data['adx'] = data['adx'].shift(1)\n",
    "\n",
    "from talib import ATR\n",
    "data['atr'] = ATR(high=data['high'], low=data['low'], close=data['close'], timeperiod=14)\n",
    "#data['atr'] = data['atr'].shift(1)\n",
    "\n",
    "from talib import SAR\n",
    "data['sar'] = SAR(high=data['high'], low=data['low'], acceleration=0.02, maximum=0.2)\n",
    "#data['sar'] = data['sar'].shift(1)\n",
    "\n",
    "from talib import TEMA\n",
    "data['tema'] = TEMA(data['close'], timeperiod=14)\n",
    "#data['tema'] = data['tema'].shift(1)\n",
    "\n",
    "from talib import ROC\n",
    "data['roc'] = ROC(data['close'], timeperiod=14)\n",
    "#data['roc'] = data['roc'].shift(1)\n",
    "\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be227ea-523f-4d8a-9445-a7ed4cd593dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_c = ('close', 'ma_9', 'sma_9', 'macd', 'signal', 'hist', 'adx', 'atr', 'sar', 'tema', 'roc')\n",
    "best_features_h = ('high', 'ma_9', 'sma_9', 'macd', 'signal', 'hist', 'adx', 'atr', 'sar', 'tema', 'roc')\n",
    "best_features_l = ('low', 'ma_9', 'sma_9', 'macd', 'signal', 'hist', 'adx', 'atr', 'sar', 'tema', 'roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be446ee3-1a7c-4015-a2b1-2367e21c9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_c = data[list(best_features_c)]\n",
    "data_target_c = data[['close']]\n",
    "\n",
    "data_input_h = data[list(best_features_h)]\n",
    "data_target_h = data[['high']]\n",
    "\n",
    "data_input_l = data[list(best_features_l)]\n",
    "data_target_l = data[['low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f04c059-6a71-4634-8257-5c56ecc1d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_c = MinMaxScaler()\n",
    "data_scaled_c = scaler_c.fit_transform(data_input_c)\n",
    "\n",
    "scaler_target_c = MinMaxScaler()\n",
    "target_scaled_c = scaler_target_c.fit_transform(data_target_c)\n",
    "\n",
    "scaler_h = MinMaxScaler()\n",
    "data_scaled_h = scaler_h.fit_transform(data_input_h)\n",
    "\n",
    "scaler_target_h = MinMaxScaler()\n",
    "target_scaled_h = scaler_target_h.fit_transform(data_target_h)\n",
    "\n",
    "scaler_l = MinMaxScaler()\n",
    "data_scaled_l = scaler_l.fit_transform(data_input_l)\n",
    "\n",
    "scaler_target_l = MinMaxScaler()\n",
    "target_scaled_l = scaler_target_l.fit_transform(data_target_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6157d58-cc70-480f-8897-3093f4051771",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 14  # Number of time steps in each sequence\n",
    "\n",
    "num_features_c = data_input_c.shape[1]\n",
    "num_features_h = data_input_h.shape[1]\n",
    "num_features_l = data_input_l.shape[1]\n",
    "\n",
    "X_features_c = data_scaled_c\n",
    "y_target_c = target_scaled_c\n",
    "X_features_h = data_scaled_h\n",
    "y_target_h = target_scaled_h\n",
    "X_features_l = data_scaled_l\n",
    "y_target_l = target_scaled_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22aceb5d-db46-4f83-a69f-a0bc878b26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create input sequences and targets\n",
    "def create_sequences(features, target, seq_length):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X_seq.append(features[i:i+seq_length])  # Input sequence\n",
    "        y_seq.append(target[i+seq_length]) # Target value (next data point)\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f580179-d331-4b50-8bf0-981ffe30d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_c, y_seq_c = create_sequences(X_features_c, y_target_c, seq_length)\n",
    "X_seq_h, y_seq_h = create_sequences(X_features_h, y_target_h, seq_length)\n",
    "X_seq_l, y_seq_l = create_sequences(X_features_l, y_target_l, seq_length)\n",
    "\n",
    "# Reshape X_seq to fit LSTM model input shape\n",
    "X_seq_c = X_seq_c.reshape(X_seq_c.shape[0], seq_length, num_features_c)\n",
    "X_seq_h = X_seq_h.reshape(X_seq_h.shape[0], seq_length, num_features_h)\n",
    "X_seq_l = X_seq_l.reshape(X_seq_l.shape[0], seq_length, num_features_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7703134-6ab1-4903-8fcd-d48c0947a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 08:11:05.418897: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-25 08:11:05.818886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-25 08:11:05.819292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-25 08:11:05.887089: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-25 08:11:06.026980: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-25 08:11:08.129177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 3s 19ms/step - loss: 0.0100 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.6738e-04 - val_loss: 0.0035\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.0281e-04 - val_loss: 0.0022\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 8.3195e-05 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 7.0732e-05 - val_loss: 0.0013\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.3838e-05 - val_loss: 0.0014\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.9044e-05 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 5.5137e-05 - val_loss: 0.0012\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1575e-05 - val_loss: 0.0011\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.9473e-05 - val_loss: 0.0010\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.8621e-05 - val_loss: 0.0011\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.7606e-05 - val_loss: 8.6688e-04\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 4.7399e-05 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.2898e-05 - val_loss: 0.0012\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.2863e-05 - val_loss: 0.0011\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.2812e-05 - val_loss: 0.0013\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.3078e-05 - val_loss: 6.9191e-04\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.4221e-05 - val_loss: 0.0010\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.0524e-05 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 4.3984e-05 - val_loss: 9.8245e-04\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.9997e-05 - val_loss: 9.2146e-04\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.8580e-05 - val_loss: 0.0011\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.1621e-05 - val_loss: 7.8071e-04\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.3558e-05 - val_loss: 8.8738e-04\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.1827e-05 - val_loss: 7.3497e-04\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.0755e-05 - val_loss: 8.0889e-04\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.0159e-05 - val_loss: 6.2478e-04\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.9911e-05 - val_loss: 8.0863e-04\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.1643e-05 - val_loss: 0.0011\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.8953e-05 - val_loss: 7.8861e-04\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.9050e-05 - val_loss: 8.7287e-04\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.6536e-05 - val_loss: 7.8782e-04\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.8857e-05 - val_loss: 6.0722e-04\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6933e-05 - val_loss: 6.4912e-04\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4800e-05 - val_loss: 7.2667e-04\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.7850e-05 - val_loss: 8.0271e-04\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.7586e-05 - val_loss: 9.1245e-04\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.8714e-05 - val_loss: 8.8951e-04\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.9708e-05 - val_loss: 8.6038e-04\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.4126e-05 - val_loss: 7.0766e-04\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.6962e-05 - val_loss: 7.6337e-04\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6185e-05 - val_loss: 6.0044e-04\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3820e-05 - val_loss: 3.6700e-04\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.7274e-05 - val_loss: 3.7975e-04\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.4835e-05 - val_loss: 4.9213e-04\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.4033e-05 - val_loss: 3.9052e-04\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.5303e-05 - val_loss: 8.1552e-04\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 4.2647e-05 - val_loss: 4.1274e-04\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.6938e-05 - val_loss: 9.5556e-04\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.6111e-05 - val_loss: 6.7785e-04\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5915e-05 - val_loss: 3.5439e-04\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.8412e-05 - val_loss: 5.1791e-04\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 3.6841e-05 - val_loss: 4.2727e-04\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.5890e-05 - val_loss: 6.7696e-04\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.2202e-05 - val_loss: 4.6579e-04\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.3592e-05 - val_loss: 5.1541e-04\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3773e-05 - val_loss: 4.7481e-04\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.2311e-05 - val_loss: 5.4920e-04\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.6313e-05 - val_loss: 6.2676e-04\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.2565e-05 - val_loss: 5.4818e-04\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.6587e-05 - val_loss: 3.8297e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb504771450>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build LSTM model\n",
    "model_c = Sequential([\n",
    "    LSTM(25, input_shape=(seq_length, num_features_c)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_c.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model with early stopping\n",
    "model_c.fit(X_seq_c, y_seq_c, epochs=100, batch_size=45, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c1c250-da2d-4733-990a-9ca673cbca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 3s 19ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 7.2667e-05 - val_loss: 0.0021\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.5729e-05 - val_loss: 0.0015\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.9774e-05 - val_loss: 0.0010\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5437e-05 - val_loss: 9.2806e-04\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6167e-05 - val_loss: 9.0233e-04\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4331e-05 - val_loss: 8.3115e-04\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.1818e-05 - val_loss: 8.8836e-04\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8176e-05 - val_loss: 8.0552e-04\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.9433e-05 - val_loss: 9.0006e-04\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8597e-05 - val_loss: 5.4722e-04\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.5813e-05 - val_loss: 7.2190e-04\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.5109e-05 - val_loss: 0.0011\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4218e-05 - val_loss: 6.5648e-04\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.3685e-05 - val_loss: 4.9595e-04\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.4719e-05 - val_loss: 7.6474e-04\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.5757e-05 - val_loss: 8.2580e-04\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.4348e-05 - val_loss: 5.4859e-04\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.2966e-05 - val_loss: 6.3238e-04\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.5063e-05 - val_loss: 7.4892e-04\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.3548e-05 - val_loss: 7.4786e-04\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.0557e-05 - val_loss: 5.9897e-04\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.2385e-05 - val_loss: 5.3349e-04\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.0699e-05 - val_loss: 4.0629e-04\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.0766e-05 - val_loss: 4.4161e-04\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.0895e-05 - val_loss: 5.3002e-04\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9082e-05 - val_loss: 5.2937e-04\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8859e-05 - val_loss: 6.8660e-04\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.0659e-05 - val_loss: 3.2096e-04\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.3731e-05 - val_loss: 5.5298e-04\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7518e-05 - val_loss: 3.9359e-04\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.7888e-05 - val_loss: 4.0382e-04\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.0100e-05 - val_loss: 3.5486e-04\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.0096e-05 - val_loss: 3.7145e-04\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.9138e-05 - val_loss: 4.6312e-04\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.7706e-05 - val_loss: 5.6531e-04\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.8100e-05 - val_loss: 3.9134e-04\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.7602e-05 - val_loss: 3.3719e-04\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.3153e-05 - val_loss: 2.8703e-04\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.2606e-05 - val_loss: 5.4620e-04\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.7704e-05 - val_loss: 3.2041e-04\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7417e-05 - val_loss: 4.1226e-04\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.7681e-05 - val_loss: 5.8620e-04\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.9530e-05 - val_loss: 3.7483e-04\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9159e-05 - val_loss: 3.2747e-04\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7079e-05 - val_loss: 3.2906e-04\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5715e-05 - val_loss: 3.5737e-04\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6121e-05 - val_loss: 3.1379e-04\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.5229e-05 - val_loss: 3.8969e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb504f0c9d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build LSTM model\n",
    "model_h = Sequential([\n",
    "    LSTM(25, input_shape=(seq_length, num_features_h)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_h.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model with early stopping\n",
    "model_h.fit(X_seq_h, y_seq_h, epochs=100, batch_size=45, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85da6bc8-1902-4ed1-873d-049ea18e3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 21ms/step - loss: 0.0140 - val_loss: 0.0031\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.8635e-04 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.4115e-04 - val_loss: 0.0033\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 1.0975e-04 - val_loss: 0.0033\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 9.0991e-05 - val_loss: 0.0031\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 8.0833e-05 - val_loss: 0.0028\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 6.9717e-05 - val_loss: 0.0035\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 6.2994e-05 - val_loss: 0.0027\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.9198e-05 - val_loss: 0.0032\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.3222e-05 - val_loss: 0.0031\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.0029e-05 - val_loss: 0.0034\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.7219e-05 - val_loss: 0.0035\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.4199e-05 - val_loss: 0.0027\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.3290e-05 - val_loss: 0.0030\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.1781e-05 - val_loss: 0.0031\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.1298e-05 - val_loss: 0.0026\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.0992e-05 - val_loss: 0.0027\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.8818e-05 - val_loss: 0.0027\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.9137e-05 - val_loss: 0.0026\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.7017e-05 - val_loss: 0.0025\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.6046e-05 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.5104e-05 - val_loss: 0.0022\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5661e-05 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.5918e-05 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.4921e-05 - val_loss: 0.0016\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6869e-05 - val_loss: 0.0022\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.2016e-05 - val_loss: 0.0020\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.2492e-05 - val_loss: 0.0020\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.4359e-05 - val_loss: 0.0019\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0931e-05 - val_loss: 0.0017\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.3628e-05 - val_loss: 0.0016\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.1542e-05 - val_loss: 0.0016\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.8968e-05 - val_loss: 0.0015\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3494e-05 - val_loss: 0.0015\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2944e-05 - val_loss: 0.0020\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.9191e-05 - val_loss: 0.0012\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.9218e-05 - val_loss: 0.0012\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.1418e-05 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.1989e-05 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7544e-05 - val_loss: 0.0014\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.0861e-05 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 3.0758e-05 - val_loss: 0.0010\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.7920e-05 - val_loss: 9.6498e-04\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.2214e-05 - val_loss: 0.0010\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8233e-05 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.8382e-05 - val_loss: 0.0010\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8279e-05 - val_loss: 7.2332e-04\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4975e-05 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.4673e-05 - val_loss: 9.1730e-04\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6254e-05 - val_loss: 6.3536e-04\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.6571e-05 - val_loss: 6.5387e-04\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.1347e-05 - val_loss: 6.7812e-04\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.5999e-05 - val_loss: 7.7252e-04\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.6973e-05 - val_loss: 7.4749e-04\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.5393e-05 - val_loss: 8.0599e-04\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.4187e-05 - val_loss: 6.0613e-04\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9613e-05 - val_loss: 6.5971e-04\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6612e-05 - val_loss: 8.4113e-04\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.7694e-05 - val_loss: 5.5486e-04\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.2992e-05 - val_loss: 7.0746e-04\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.8451e-05 - val_loss: 9.9812e-04\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.8909e-05 - val_loss: 5.0934e-04\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.3042e-05 - val_loss: 4.4473e-04\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.4835e-05 - val_loss: 8.2236e-04\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.4886e-05 - val_loss: 4.8361e-04\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7501e-05 - val_loss: 4.5497e-04\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4023e-05 - val_loss: 6.2811e-04\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6771e-05 - val_loss: 8.0900e-04\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9771e-05 - val_loss: 4.0067e-04\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.2464e-05 - val_loss: 4.7983e-04\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7672e-05 - val_loss: 7.0111e-04\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5941e-05 - val_loss: 4.8857e-04\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2266e-05 - val_loss: 7.7224e-04\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4028e-05 - val_loss: 4.3969e-04\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.4342e-05 - val_loss: 3.8881e-04\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.3611e-05 - val_loss: 4.0254e-04\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.1548e-05 - val_loss: 2.6141e-04\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.6022e-05 - val_loss: 4.4354e-04\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.3411e-05 - val_loss: 3.0322e-04\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.4653e-05 - val_loss: 4.0968e-04\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7092e-05 - val_loss: 3.0154e-04\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.6480e-05 - val_loss: 5.5158e-04\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.1340e-05 - val_loss: 3.9353e-04\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.2532e-05 - val_loss: 4.5054e-04\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7067e-05 - val_loss: 4.0131e-04\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.3752e-05 - val_loss: 2.1222e-04\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6165e-05 - val_loss: 1.7923e-04\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.6158e-05 - val_loss: 3.0735e-04\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7406e-05 - val_loss: 5.2206e-04\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4890e-05 - val_loss: 2.7774e-04\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.3045e-05 - val_loss: 4.4845e-04\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.2563e-05 - val_loss: 3.4028e-04\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.1777e-05 - val_loss: 1.8115e-04\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.5487e-05 - val_loss: 4.6948e-04\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.2167e-05 - val_loss: 2.9437e-04\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.1735e-05 - val_loss: 2.2299e-04\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 2.3371e-05 - val_loss: 4.8301e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb5049fe650>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build LSTM model\n",
    "model_l = Sequential([\n",
    "    LSTM(25, input_shape=(seq_length, num_features_l)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_l.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model with early stopping\n",
    "model_l.fit(X_seq_l, y_seq_l, epochs=100, batch_size=45, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c63bf82-52f5-4b99-a1f5-9068ea0994d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Serialize and save the model to a file\n",
    "with open('model_c.pkl', 'wb') as file:\n",
    "    pickle.dump(model_c, file)\n",
    "\n",
    "with open('model_h.pkl', 'wb') as file:\n",
    "    pickle.dump(model_h, file)\n",
    "\n",
    "with open('model_l.pkl', 'wb') as file:\n",
    "    pickle.dump(model_l, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6169b-4202-471b-ab42-58284ac535d9",
   "metadata": {},
   "source": [
    "### data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bb44124-7c1f-4bd9-b14b-95cad232b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "directory = 'data'\n",
    "\n",
    "df_data = dict()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    symbol_pattern = re.match(r'([^_]+)_', file)\n",
    "    symbol = symbol_pattern.group(1)\n",
    "    df_data[symbol] = pd.read_csv(os.path.join(directory, file))\n",
    "    df_data[symbol].rename(columns={'Date': 'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c5b047b-6f72-4d14-9bf0-a118ffba79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in df_data:\n",
    "    from talib import RSI\n",
    "    df_data[symbol]['rsi_14'] = RSI(df_data[symbol]['close'], timeperiod=14)\n",
    "    #df_data[symbol]['rsi_14'] = df_data[symbol]['rsi_14'].shift(1)\n",
    "    \n",
    "    from talib import MA, SMA, EMA, WMA\n",
    "    df_data[symbol]['ma_9'] = MA(df_data[symbol]['close'], timeperiod=9)\n",
    "    #df_data[symbol]['ma_9'] = df_data[symbol]['ma_9'].shift(1)\n",
    "    df_data[symbol]['sma_9'] = SMA(df_data[symbol]['close'], timeperiod=9)\n",
    "    #df_data[symbol]['sma_9'] = df_data[symbol]['sma_9'].shift(1)\n",
    "    df_data[symbol]['wma_9'] = WMA(df_data[symbol]['close'], timeperiod=9)\n",
    "    #df_data[symbol]['wma_9'] = df_data[symbol]['wma_9'].shift(1)\n",
    "    \n",
    "    from talib import MACD\n",
    "    df_data[symbol]['macd'], df_data[symbol]['signal'], df_data[symbol]['hist'] = MACD(df_data[symbol]['close'])\n",
    "    #df_data[symbol]['macd'] = df_data[symbol]['macd'].shift(1)\n",
    "    #df_data[symbol]['signal'] = df_data[symbol]['signal'].shift(1)\n",
    "    #df_data[symbol]['hist'] = df_data[symbol]['hist'].shift(1)\n",
    "    \n",
    "    from talib import ADX\n",
    "    df_data[symbol]['adx'] = ADX(df_data[symbol]['high'], df_data[symbol]['low'], df_data[symbol]['close'])\n",
    "    #df_data[symbol]['adx'] = df_data[symbol]['adx'].shift(1)\n",
    "    \n",
    "    from talib import ATR\n",
    "    df_data[symbol]['atr'] = ATR(high=df_data[symbol]['high'], low=df_data[symbol]['low'], close=df_data[symbol]['close'], timeperiod=14)\n",
    "    #df_data[symbol]['atr'] = df_data[symbol]['atr'].shift(1)\n",
    "    \n",
    "    from talib import SAR\n",
    "    df_data[symbol]['sar'] = SAR(high=df_data[symbol]['high'], low=df_data[symbol]['low'], acceleration=0.02, maximum=0.2)\n",
    "    #df_data[symbol]['sar'] = df_data[symbol]['sar'].shift(1)\n",
    "    \n",
    "    from talib import TEMA\n",
    "    df_data[symbol]['tema'] = TEMA(df_data[symbol]['close'], timeperiod=14)\n",
    "    #df_data[symbol]['tema'] = df_data[symbol]['tema'].shift(1)\n",
    "    \n",
    "    from talib import ROC\n",
    "    df_data[symbol]['roc'] = ROC(df_data[symbol]['close'], timeperiod=14)\n",
    "    #df_data[symbol]['roc'] = df_data[symbol]['roc'].shift(1)\n",
    "    \n",
    "    df_data[symbol].dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57673bfb-52b0-4a31-aa43-ba757ba6fa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 VRTX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "2 MDLZ\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "3 TMO\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "4 UNH\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "5 TJX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "6 AAPL\n",
      "156/156 [==============================] - 0s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "7 BKNG\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "8 V\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "123/123 [==============================] - 0s 4ms/step\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "9 LOW\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "10 PM\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "123/123 [==============================] - 1s 4ms/step\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "11 CMCSA\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "12 HD\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "13 GOOG\n",
      "151/151 [==============================] - 1s 4ms/step\n",
      "151/151 [==============================] - 1s 3ms/step\n",
      "151/151 [==============================] - 1s 4ms/step\n",
      "14 AXP\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "15 NVDA\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "16 SBUX\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "17 PG\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "18 SPGI\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "19 AMZN\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "20 ORCL\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "21 NKE\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 2s 11ms/step\n",
      "22 CVX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "23 SYK\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "24 TMUS\n",
      "130/130 [==============================] - 0s 3ms/step\n",
      "130/130 [==============================] - 1s 4ms/step\n",
      "130/130 [==============================] - 0s 3ms/step\n",
      "25 XOM\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "26 LRCX\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "27 AMAT\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "28 HON\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "29 ABNB\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 5ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "30 GE\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "31 TSLA\n",
      "105/105 [==============================] - 0s 4ms/step\n",
      "105/105 [==============================] - 0s 3ms/step\n",
      "105/105 [==============================] - 1s 7ms/step\n",
      "32 MRK\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "33 BSX\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "34 UPS\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "35 LLY\n",
      "156/156 [==============================] - 0s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "36 VZ\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "37 T\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "38 MSFT\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "39 CI\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "40 ETN\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "41 JNJ\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "42 PANW\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "89/89 [==============================] - 0s 4ms/step\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "43 MDT\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "44 DE\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "45 AVGO\n",
      "112/112 [==============================] - 0s 3ms/step\n",
      "112/112 [==============================] - 0s 4ms/step\n",
      "112/112 [==============================] - 0s 4ms/step\n",
      "46 ELV\n",
      "156/156 [==============================] - 1s 7ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "47 SHOP\n",
      "67/67 [==============================] - 0s 5ms/step\n",
      "67/67 [==============================] - 0s 4ms/step\n",
      "67/67 [==============================] - 0s 4ms/step\n",
      "48 DHR\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "49 BA\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "50 C\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "51 META\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "90/90 [==============================] - 0s 4ms/step\n",
      "90/90 [==============================] - 0s 5ms/step\n",
      "52 SCHW\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "53 CB\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "54 MCD\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "55 LMT\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "56 BMY\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "57 QCOM\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "58 ABT\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "59 NOW\n",
      "89/89 [==============================] - 0s 4ms/step\n",
      "89/89 [==============================] - 0s 4ms/step\n",
      "89/89 [==============================] - 0s 5ms/step\n",
      "60 IBM\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "61 ISRG\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "62 CAT\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "63 WMT\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "64 CSCO\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "65 MMC\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "66 DIS\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "67 MS\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "68 CRM\n",
      "152/152 [==============================] - 1s 4ms/step\n",
      "152/152 [==============================] - 1s 4ms/step\n",
      "152/152 [==============================] - 1s 4ms/step\n",
      "69 PFE\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "70 UNP\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "71 COST\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "72 INTU\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "73 MA\n",
      "137/137 [==============================] - 0s 3ms/step\n",
      "137/137 [==============================] - 1s 4ms/step\n",
      "137/137 [==============================] - 1s 4ms/step\n",
      "74 BLK\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "75 REGN\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "76 ADI\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 0s 3ms/step\n",
      "77 AMD\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "78 TXN\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "79 COP\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "80 PGR\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "81 ADP\n",
      "156/156 [==============================] - 1s 6ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "82 BX\n",
      "129/129 [==============================] - 1s 4ms/step\n",
      "129/129 [==============================] - 1s 5ms/step\n",
      "129/129 [==============================] - 0s 4ms/step\n",
      "83 CVS\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "84 AMGN\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "85 RTX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "86 KO\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "87 UBER\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "35/35 [==============================] - 0s 5ms/step\n",
      "35/35 [==============================] - 0s 5ms/step\n",
      "88 JPM\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "89 GS\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "90 ^NDX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "91 ABBV\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "85/85 [==============================] - 0s 5ms/step\n",
      "85/85 [==============================] - 0s 5ms/step\n",
      "92 PEP\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "93 ACN\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "94 NEE\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "95 INTC\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "96 LIN\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "97 BAC\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "98 WFC\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "99 NFLX\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "100 ADBE\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n",
      "156/156 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#df_input = dict()\n",
    "df_pred = dict()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for symbol in df_data:\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    scaler_input = MinMaxScaler()\n",
    "    data_backup_c_scaled = scaler_input.fit_transform(df_data[symbol][list(best_features_c)])\n",
    "    scaler_target = MinMaxScaler()\n",
    "    target_backup_c_scaled = scaler_target.fit_transform(df_data[symbol][['close']])\n",
    "    X_b_c, y_b_c = create_sequences(data_backup_c_scaled, target_backup_c_scaled, seq_length)\n",
    "    X_b_c = X_b_c.reshape(X_b_c.shape[0], seq_length, num_features_c)\n",
    "    #df_input[symbol]['input_c'] = X_b_c\n",
    "\n",
    "    print(count, symbol)\n",
    "    y_pred_c = model_c.predict(X_b_c)\n",
    "    y_pred_c = scaler_target.inverse_transform(y_pred_c)\n",
    "\n",
    "    scaler_input = MinMaxScaler()\n",
    "    data_backup_h_scaled = scaler_input.fit_transform(df_data[symbol][list(best_features_h)])\n",
    "    scaler_target = MinMaxScaler()\n",
    "    target_backup_h_scaled = scaler_target.fit_transform(df_data[symbol][['high']])\n",
    "    X_b_h, y_b_h = create_sequences(data_backup_h_scaled, target_backup_h_scaled, seq_length)\n",
    "    X_b_h = X_b_h.reshape(X_b_h.shape[0], seq_length, num_features_h)\n",
    "    #df_input[symbol]['input_h'] = X_b_h\n",
    "\n",
    "    y_pred_h = model_h.predict(X_b_h)\n",
    "    y_pred_h = scaler_target.inverse_transform(y_pred_h)\n",
    "\n",
    "    scaler_input = MinMaxScaler()\n",
    "    data_backup_l_scaled = scaler_input.fit_transform(df_data[symbol][list(best_features_l)])\n",
    "    scaler_target = MinMaxScaler()\n",
    "    target_backup_l_scaled = scaler_target.fit_transform(df_data[symbol][['low']])\n",
    "    X_b_l, y_b_l = create_sequences(data_backup_l_scaled, target_backup_l_scaled, seq_length)\n",
    "    X_b_l = X_b_l.reshape(X_b_l.shape[0], seq_length, num_features_l)\n",
    "    #df_input[symbol]['input_l'] = X_b_l\n",
    "\n",
    "    y_pred_l = model_l.predict(X_b_l)\n",
    "    y_pred_l = scaler_target.inverse_transform(y_pred_l)\n",
    "\n",
    "    #dict_data = {'input_c': X_b_c, 'input_h': X_b_h, 'input_l': X_b_l}\n",
    "    #df_input[symbol] = dict_data\n",
    "    #print(symbol)\n",
    "\n",
    "    dict_pred = {'pred_c':y_pred_c, 'pred_h':y_pred_h, 'pred_l':y_pred_l}\n",
    "    df_pred[symbol] = dict_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63dbe91f-c05d-4489-ba8d-39f450eb14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 METRICS FOR VRTX:\n",
      "score close: 8.073058508366467\n",
      "score high: 3.01696394016465\n",
      "score low: 3.4343664035260915\n",
      "- R2 METRICS FOR VRTX:\n",
      "r2 close: 0.9903984090882947\n",
      "r2 high: 0.9970534082037548\n",
      "r2 low: 0.9977007543272582\n",
      "2 METRICS FOR MDLZ:\n",
      "score close: 0.6284558116192799\n",
      "score high: 0.5685444529276775\n",
      "score low: 0.5428047019315053\n",
      "- R2 METRICS FOR MDLZ:\n",
      "r2 close: 0.9946362762448319\n",
      "r2 high: 0.9954464243009632\n",
      "r2 low: 0.9955411411821588\n",
      "3 METRICS FOR TMO:\n",
      "score close: 7.298170739675621\n",
      "score high: 4.118957081377267\n",
      "score low: 3.8101911456709407\n",
      "- R2 METRICS FOR TMO:\n",
      "r2 close: 0.9969322723874865\n",
      "r2 high: 0.9979472838876264\n",
      "r2 low: 0.998939564767169\n",
      "4 METRICS FOR UNH:\n",
      "score close: 9.74447541552854\n",
      "score high: 5.2261998364245565\n",
      "score low: 3.66919670430532\n",
      "- R2 METRICS FOR UNH:\n",
      "r2 close: 0.9939326902986354\n",
      "r2 high: 0.996885183566923\n",
      "r2 low: 0.9985395957434197\n",
      "5 METRICS FOR TJX:\n",
      "score close: 0.6178801428362068\n",
      "score high: 0.6881585825877975\n",
      "score low: 1.1066528933115274\n",
      "- R2 METRICS FOR TJX:\n",
      "r2 close: 0.9979065818177553\n",
      "r2 high: 0.998130695606538\n",
      "r2 low: 0.9966442381286184\n",
      "6 METRICS FOR AAPL:\n",
      "score close: 2.583671894629699\n",
      "score high: 1.8587054737781392\n",
      "score low: 1.0455869031780172\n",
      "- R2 METRICS FOR AAPL:\n",
      "r2 close: 0.9961573453251253\n",
      "r2 high: 0.9971318146087716\n",
      "r2 low: 0.9988466879190443\n",
      "7 METRICS FOR BKNG:\n",
      "score close: 26.232650302996838\n",
      "score high: 25.191165744827455\n",
      "score low: 43.016038777071785\n",
      "- R2 METRICS FOR BKNG:\n",
      "r2 close: 0.9974619119664365\n",
      "r2 high: 0.9978775808650919\n",
      "r2 low: 0.9963405902244392\n",
      "8 METRICS FOR V:\n",
      "score close: 4.895055173520256\n",
      "score high: 2.097166105667811\n",
      "score low: 2.949555048496253\n",
      "- R2 METRICS FOR V:\n",
      "r2 close: 0.9939040666384724\n",
      "r2 high: 0.9978146116024055\n",
      "r2 low: 0.9978222101873261\n",
      "9 METRICS FOR LOW:\n",
      "score close: 2.443301854650658\n",
      "score high: 1.414209304564449\n",
      "score low: 2.2083757919480043\n",
      "- R2 METRICS FOR LOW:\n",
      "r2 close: 0.9970024622728298\n",
      "r2 high: 0.9983011600476219\n",
      "r2 low: 0.9979679700613973\n",
      "10 METRICS FOR PM:\n",
      "score close: 1.4368035877781076\n",
      "score high: 1.140684649496397\n",
      "score low: 1.2428844946852273\n",
      "- R2 METRICS FOR PM:\n",
      "r2 close: 0.9895059561643857\n",
      "r2 high: 0.9931219871856266\n",
      "r2 low: 0.9909016321468915\n",
      "11 METRICS FOR CMCSA:\n",
      "score close: 0.8197081399251178\n",
      "score high: 0.3949304830597108\n",
      "score low: 0.4004539028229005\n",
      "- R2 METRICS FOR CMCSA:\n",
      "r2 close: 0.9952727064548359\n",
      "r2 high: 0.9981754431548884\n",
      "r2 low: 0.9981413800272534\n",
      "12 METRICS FOR HD:\n",
      "score close: 2.337442453989542\n",
      "score high: 2.052886857565148\n",
      "score low: 3.6595474388704723\n",
      "- R2 METRICS FOR HD:\n",
      "r2 close: 0.9983390292663511\n",
      "r2 high: 0.9987802392906264\n",
      "r2 low: 0.9978750141384942\n",
      "13 METRICS FOR GOOG:\n",
      "score close: 2.1524416928665118\n",
      "score high: 1.0815222052210647\n",
      "score low: 1.0206014148331637\n",
      "- R2 METRICS FOR GOOG:\n",
      "r2 close: 0.9936678290653178\n",
      "r2 high: 0.996988501803195\n",
      "r2 low: 0.9984135710850099\n",
      "14 METRICS FOR AXP:\n",
      "score close: 2.148248743915175\n",
      "score high: 1.6282398346437508\n",
      "score low: 2.356502056696329\n",
      "- R2 METRICS FOR AXP:\n",
      "r2 close: 0.9933064582551958\n",
      "r2 high: 0.9960575005575335\n",
      "r2 low: 0.9945855940215581\n",
      "15 METRICS FOR NVDA:\n",
      "score close: 9.164402194956134\n",
      "score high: 7.249239437625499\n",
      "score low: 2.8981708842303617\n",
      "- R2 METRICS FOR NVDA:\n",
      "r2 close: 0.9865902543024685\n",
      "r2 high: 0.9904676320254693\n",
      "r2 low: 0.9965928348491087\n",
      "16 METRICS FOR SBUX:\n",
      "score close: 1.8991355503658693\n",
      "score high: 0.8074206414950421\n",
      "score low: 1.2795256063162563\n",
      "- R2 METRICS FOR SBUX:\n",
      "r2 close: 0.9948886797589752\n",
      "r2 high: 0.998307688033161\n",
      "r2 low: 0.9975512951422649\n",
      "17 METRICS FOR PG:\n",
      "score close: 2.2232391127620836\n",
      "score high: 1.5193880816540086\n",
      "score low: 2.519223282136113\n",
      "- R2 METRICS FOR PG:\n",
      "r2 close: 0.9916401392332967\n",
      "r2 high: 0.9952950965687709\n",
      "r2 low: 0.9920562516874163\n",
      "18 METRICS FOR SPGI:\n",
      "score close: 8.96439492003506\n",
      "score high: 2.8237619239163694\n",
      "score low: 4.064457882647534\n",
      "- R2 METRICS FOR SPGI:\n",
      "r2 close: 0.9929527478090182\n",
      "r2 high: 0.998289597468987\n",
      "r2 low: 0.9981288627762229\n",
      "19 METRICS FOR AMZN:\n",
      "score close: 3.4176568635039724\n",
      "score high: 1.2879198754168897\n",
      "score low: 1.8036564153839785\n",
      "- R2 METRICS FOR AMZN:\n",
      "r2 close: 0.9937717582473694\n",
      "r2 high: 0.9977120896658662\n",
      "r2 low: 0.9979263099313963\n",
      "20 METRICS FOR ORCL:\n",
      "score close: 1.5157823254305673\n",
      "score high: 1.1824979198026848\n",
      "score low: 0.6841581670155965\n",
      "- R2 METRICS FOR ORCL:\n",
      "r2 close: 0.9940871095067213\n",
      "r2 high: 0.9956423512052666\n",
      "r2 low: 0.9980327592317696\n",
      "21 METRICS FOR NKE:\n",
      "score close: 3.488895813336813\n",
      "score high: 1.343700781691984\n",
      "score low: 1.2371294914000484\n",
      "- R2 METRICS FOR NKE:\n",
      "r2 close: 0.9919209916991703\n",
      "r2 high: 0.9977313728231494\n",
      "r2 low: 0.9977705875939072\n",
      "22 METRICS FOR CVX:\n",
      "score close: 2.542181339034115\n",
      "score high: 1.7966833597206207\n",
      "score low: 1.8768522055752306\n",
      "- R2 METRICS FOR CVX:\n",
      "r2 close: 0.987174488035082\n",
      "r2 high: 0.9924248088630343\n",
      "r2 low: 0.9916151728479496\n",
      "23 METRICS FOR SYK:\n",
      "score close: 5.452234491478487\n",
      "score high: 2.2784250604100973\n",
      "score low: 2.809600208849313\n",
      "- R2 METRICS FOR SYK:\n",
      "r2 close: 0.9924044518891636\n",
      "r2 high: 0.997569347675303\n",
      "r2 low: 0.9975348652163052\n",
      "24 METRICS FOR TMUS:\n",
      "score close: 3.0259339271942314\n",
      "score high: 1.6459507152064914\n",
      "score low: 1.2809622685114543\n",
      "- R2 METRICS FOR TMUS:\n",
      "r2 close: 0.992582267857098\n",
      "r2 high: 0.9967710411073417\n",
      "r2 low: 0.9977855949996375\n",
      "25 METRICS FOR XOM:\n",
      "score close: 1.4471872873574376\n",
      "score high: 1.2213635670612135\n",
      "score low: 1.1661858447584283\n",
      "- R2 METRICS FOR XOM:\n",
      "r2 close: 0.9865909338189511\n",
      "r2 high: 0.9905572650717336\n",
      "r2 low: 0.9907871251274984\n",
      "26 METRICS FOR LRCX:\n",
      "score close: 9.417725098228837\n",
      "score high: 5.949693160076218\n",
      "score low: 4.875046294377032\n",
      "- R2 METRICS FOR LRCX:\n",
      "r2 close: 0.9957932741774647\n",
      "r2 high: 0.9969918063145257\n",
      "r2 low: 0.9981068101279524\n",
      "27 METRICS FOR AMAT:\n",
      "score close: 1.786142562000627\n",
      "score high: 1.4773387527848822\n",
      "score low: 1.0221746935901872\n",
      "- R2 METRICS FOR AMAT:\n",
      "r2 close: 0.9959735003337259\n",
      "r2 high: 0.9966714979444979\n",
      "r2 low: 0.9980399068098325\n",
      "28 METRICS FOR HON:\n",
      "score close: 2.576562817508437\n",
      "score high: 1.6421011457481538\n",
      "score low: 1.91063173209807\n",
      "- R2 METRICS FOR HON:\n",
      "r2 close: 0.996128142562667\n",
      "r2 high: 0.9980050334741943\n",
      "r2 low: 0.9978046803451386\n",
      "29 METRICS FOR ABNB:\n",
      "score close: 5.732788107278464\n",
      "score high: 5.082850999098557\n",
      "score low: 5.32822294435301\n",
      "- R2 METRICS FOR ABNB:\n",
      "r2 close: 0.9278900910149376\n",
      "r2 high: 0.9447923041558141\n",
      "r2 low: 0.9309025090599754\n",
      "30 METRICS FOR GE:\n",
      "score close: 3.274015959008152\n",
      "score high: 2.2004153098447254\n",
      "score low: 1.7983733655937226\n",
      "- R2 METRICS FOR GE:\n",
      "r2 close: 0.9912965702838064\n",
      "r2 high: 0.9954804187574312\n",
      "r2 low: 0.9967293941755592\n",
      "31 METRICS FOR TSLA:\n",
      "score close: 8.488662908868244\n",
      "score high: 4.663703261654325\n",
      "score low: 3.6319064068587674\n",
      "- R2 METRICS FOR TSLA:\n",
      "r2 close: 0.988915652724867\n",
      "r2 high: 0.994882380139318\n",
      "r2 low: 0.994617378351903\n",
      "32 METRICS FOR MRK:\n",
      "score close: 1.9013336836573589\n",
      "score high: 0.8977950877453907\n",
      "score low: 1.0711418316546215\n",
      "- R2 METRICS FOR MRK:\n",
      "r2 close: 0.9899445346695082\n",
      "r2 high: 0.9962779297411866\n",
      "r2 low: 0.9962319148693015\n",
      "33 METRICS FOR BSX:\n",
      "score close: 0.9583447170066067\n",
      "score high: 0.514672951430202\n",
      "score low: 0.624490488676661\n",
      "- R2 METRICS FOR BSX:\n",
      "r2 close: 0.9934255332969969\n",
      "r2 high: 0.9973639359844849\n",
      "r2 low: 0.9965540149294301\n",
      "34 METRICS FOR UPS:\n",
      "score close: 3.233807094221613\n",
      "score high: 1.7292975559770822\n",
      "score low: 1.5947915126999699\n",
      "- R2 METRICS FOR UPS:\n",
      "r2 close: 0.9910396764992316\n",
      "r2 high: 0.9960418995285472\n",
      "r2 low: 0.9966715222340694\n",
      "35 METRICS FOR LLY:\n",
      "score close: 7.960344215377746\n",
      "score high: 7.91057643928681\n",
      "score low: 4.622918396685497\n",
      "- R2 METRICS FOR LLY:\n",
      "r2 close: 0.9920185845290027\n",
      "r2 high: 0.9933396065171812\n",
      "r2 low: 0.996970524293602\n",
      "36 METRICS FOR VZ:\n",
      "score close: 0.9357483266347862\n",
      "score high: 0.6594465110196644\n",
      "score low: 1.1646736022458977\n",
      "- R2 METRICS FOR VZ:\n",
      "r2 close: 0.9865915610224336\n",
      "r2 high: 0.9922714740049114\n",
      "r2 low: 0.9822099756080048\n",
      "37 METRICS FOR T:\n",
      "score close: 0.5129281702769329\n",
      "score high: 0.336091384159992\n",
      "score low: 0.3322572037876849\n",
      "- R2 METRICS FOR T:\n",
      "r2 close: 0.9768019761737474\n",
      "r2 high: 0.9883818235949936\n",
      "r2 low: 0.9877858636403845\n",
      "38 METRICS FOR MSFT:\n",
      "score close: 3.57276452688807\n",
      "score high: 3.214239647302283\n",
      "score low: 1.71184897748342\n",
      "- R2 METRICS FOR MSFT:\n",
      "r2 close: 0.9973199636347826\n",
      "r2 high: 0.9973195765131082\n",
      "r2 low: 0.9989578285879481\n",
      "39 METRICS FOR CI:\n",
      "score close: 5.220937539487479\n",
      "score high: 2.5035269760223757\n",
      "score low: 2.2739874958513253\n",
      "- R2 METRICS FOR CI:\n",
      "r2 close: 0.9942159840668819\n",
      "r2 high: 0.9978074186494342\n",
      "r2 low: 0.9979851976575226\n",
      "40 METRICS FOR ETN:\n",
      "score close: 3.119990234872902\n",
      "score high: 1.5990545667318934\n",
      "score low: 1.4380904090452387\n",
      "- R2 METRICS FOR ETN:\n",
      "r2 close: 0.9935005218790925\n",
      "r2 high: 0.996857391195317\n",
      "r2 low: 0.9977668680430462\n",
      "41 METRICS FOR JNJ:\n",
      "score close: 3.3506484265308303\n",
      "score high: 1.306451186214585\n",
      "score low: 1.1333448486634525\n",
      "- R2 METRICS FOR JNJ:\n",
      "r2 close: 0.9905260252368236\n",
      "r2 high: 0.9973853650785459\n",
      "r2 low: 0.9980106107458345\n",
      "42 METRICS FOR PANW:\n",
      "score close: 3.993145029157727\n",
      "score high: 2.7557485521071614\n",
      "score low: 2.1902823952511925\n",
      "- R2 METRICS FOR PANW:\n",
      "r2 close: 0.9935990671021966\n",
      "r2 high: 0.9962848760246572\n",
      "r2 low: 0.9968464872026631\n",
      "43 METRICS FOR MDT:\n",
      "score close: 3.3528358045830786\n",
      "score high: 1.309769167383033\n",
      "score low: 1.0822710692164412\n",
      "- R2 METRICS FOR MDT:\n",
      "r2 close: 0.9779237904972538\n",
      "r2 high: 0.99465054654501\n",
      "r2 low: 0.9955794106314801\n",
      "44 METRICS FOR DE:\n",
      "score close: 5.707638383581936\n",
      "score high: 3.600722177727635\n",
      "score low: 2.5854335126149137\n",
      "- R2 METRICS FOR DE:\n",
      "r2 close: 0.9950591729221689\n",
      "r2 high: 0.9965286211477689\n",
      "r2 low: 0.9982496810680201\n",
      "45 METRICS FOR AVGO:\n",
      "score close: 20.608002273601553\n",
      "score high: 16.353243327888368\n",
      "score low: 6.2481225172322645\n",
      "- R2 METRICS FOR AVGO:\n",
      "r2 close: 0.9894446678141918\n",
      "r2 high: 0.9923176681444625\n",
      "r2 low: 0.9980688943395385\n",
      "46 METRICS FOR ELV:\n",
      "score close: 5.824138573183114\n",
      "score high: 4.112605423525156\n",
      "score low: 3.0293954370491005\n",
      "- R2 METRICS FOR ELV:\n",
      "r2 close: 0.9961117910503797\n",
      "r2 high: 0.9974487646415091\n",
      "r2 low: 0.9985551507486502\n",
      "47 METRICS FOR SHOP:\n",
      "score close: 3.461354100691825\n",
      "score high: 1.9466896531487232\n",
      "score low: 2.530560006378729\n",
      "- R2 METRICS FOR SHOP:\n",
      "r2 close: 0.9878679709127588\n",
      "r2 high: 0.9953375038755513\n",
      "r2 low: 0.9932167143686479\n",
      "48 METRICS FOR DHR:\n",
      "score close: 3.5482359097185863\n",
      "score high: 2.8894042426802544\n",
      "score low: 1.5679251073354699\n",
      "- R2 METRICS FOR DHR:\n",
      "r2 close: 0.9964291050744695\n",
      "r2 high: 0.9964714297484222\n",
      "r2 low: 0.9987076302261798\n",
      "49 METRICS FOR BA:\n",
      "score close: 4.110882680578883\n",
      "score high: 4.885899091437159\n",
      "score low: 7.725652598568713\n",
      "- R2 METRICS FOR BA:\n",
      "r2 close: 0.9938380936200386\n",
      "r2 high: 0.9943339120680622\n",
      "r2 low: 0.9890146748872618\n",
      "50 METRICS FOR C:\n",
      "score close: 11.973525788123352\n",
      "score high: 4.977227190316444\n",
      "score low: 6.916086479554695\n",
      "- R2 METRICS FOR C:\n",
      "r2 close: 0.9920151310469293\n",
      "r2 high: 0.9982746276990531\n",
      "r2 low: 0.9975855861308454\n",
      "51 METRICS FOR META:\n",
      "score close: 4.9656135133749935\n",
      "score high: 4.23515098119862\n",
      "score low: 4.69468746318219\n",
      "- R2 METRICS FOR META:\n",
      "r2 close: 0.9922563764998598\n",
      "r2 high: 0.994963874602276\n",
      "r2 low: 0.9944334064130705\n",
      "52 METRICS FOR SCHW:\n",
      "score close: 0.8361297898503193\n",
      "score high: 0.8928290962694161\n",
      "score low: 1.1567383792984438\n",
      "- R2 METRICS FOR SCHW:\n",
      "r2 close: 0.9950565147914858\n",
      "r2 high: 0.9957739574573953\n",
      "r2 low: 0.9937314871654475\n",
      "53 METRICS FOR CB:\n",
      "score close: 2.456199193671046\n",
      "score high: 1.69843902894292\n",
      "score low: 1.654650777027789\n",
      "- R2 METRICS FOR CB:\n",
      "r2 close: 0.9953231523696636\n",
      "r2 high: 0.9972163270280934\n",
      "r2 low: 0.9975061323341117\n",
      "54 METRICS FOR MCD:\n",
      "score close: 2.797664429768022\n",
      "score high: 2.1840674132228375\n",
      "score low: 3.1112904050742767\n",
      "- R2 METRICS FOR MCD:\n",
      "r2 close: 0.9961270997836008\n",
      "r2 high: 0.9976613760264244\n",
      "r2 low: 0.9973653327330219\n",
      "55 METRICS FOR LMT:\n",
      "score close: 7.331549881165289\n",
      "score high: 3.2239228489887295\n",
      "score low: 4.351488715482047\n",
      "- R2 METRICS FOR LMT:\n",
      "r2 close: 0.9949892347566103\n",
      "r2 high: 0.9982641441482953\n",
      "r2 low: 0.9979950139607916\n",
      "56 METRICS FOR BMY:\n",
      "score close: 0.8646556383155914\n",
      "score high: 0.7334084062691194\n",
      "score low: 0.7176572428170935\n",
      "- R2 METRICS FOR BMY:\n",
      "r2 close: 0.9949445399012466\n",
      "r2 high: 0.9963897444622651\n",
      "r2 low: 0.996312546911152\n",
      "57 METRICS FOR QCOM:\n",
      "score close: 4.4407831218826725\n",
      "score high: 2.5598974940288497\n",
      "score low: 2.235527659037027\n",
      "- R2 METRICS FOR QCOM:\n",
      "r2 close: 0.9770741414306804\n",
      "r2 high: 0.9907748848139551\n",
      "r2 low: 0.992437364294365\n",
      "58 METRICS FOR ABT:\n",
      "score close: 3.1502831725231615\n",
      "score high: 1.3327386434777195\n",
      "score low: 0.7706765998319449\n",
      "- R2 METRICS FOR ABT:\n",
      "r2 close: 0.989027769649203\n",
      "r2 high: 0.996745649446336\n",
      "r2 low: 0.9986756090737839\n",
      "59 METRICS FOR NOW:\n",
      "score close: 12.1230034181997\n",
      "score high: 7.7913655667437585\n",
      "score low: 7.1950602539825175\n",
      "- R2 METRICS FOR NOW:\n",
      "r2 close: 0.9942915677420336\n",
      "r2 high: 0.9964121266069098\n",
      "r2 low: 0.9970821606976935\n",
      "60 METRICS FOR IBM:\n",
      "score close: 2.6614778495696654\n",
      "score high: 2.0751131034759154\n",
      "score low: 1.9298408569581058\n",
      "- R2 METRICS FOR IBM:\n",
      "r2 close: 0.9887025582702651\n",
      "r2 high: 0.9924183322571475\n",
      "r2 low: 0.9932200446945757\n",
      "61 METRICS FOR ISRG:\n",
      "score close: 6.494605968535381\n",
      "score high: 2.815902511147131\n",
      "score low: 3.7686513783462554\n",
      "- R2 METRICS FOR ISRG:\n",
      "r2 close: 0.9930012615101623\n",
      "r2 high: 0.9970140231342156\n",
      "r2 low: 0.9973979429520843\n",
      "62 METRICS FOR CAT:\n",
      "score close: 4.914479872692062\n",
      "score high: 3.414923415126571\n",
      "score low: 2.1112292722525847\n",
      "- R2 METRICS FOR CAT:\n",
      "r2 close: 0.9899843737493433\n",
      "r2 high: 0.9932411128936774\n",
      "r2 low: 0.9970847013296994\n",
      "63 METRICS FOR WMT:\n",
      "score close: 0.5173448771358015\n",
      "score high: 0.44528152645831126\n",
      "score low: 0.6455824886459902\n",
      "- R2 METRICS FOR WMT:\n",
      "r2 close: 0.9965748515755354\n",
      "r2 high: 0.9974300059590183\n",
      "r2 low: 0.9955113358838898\n",
      "64 METRICS FOR CSCO:\n",
      "score close: 0.8169967768182717\n",
      "score high: 0.5276255711015448\n",
      "score low: 0.5089768553354654\n",
      "- R2 METRICS FOR CSCO:\n",
      "r2 close: 0.9932414133333819\n",
      "r2 high: 0.9965430463720008\n",
      "r2 low: 0.9965959887966847\n",
      "65 METRICS FOR MMC:\n",
      "score close: 2.033683419514851\n",
      "score high: 1.0186849180474338\n",
      "score low: 1.3605301765074211\n",
      "- R2 METRICS FOR MMC:\n",
      "r2 close: 0.9969988699733839\n",
      "r2 high: 0.9983727301069217\n",
      "r2 low: 0.9983574978247063\n",
      "66 METRICS FOR DIS:\n",
      "score close: 2.15381743362151\n",
      "score high: 1.3916128250489754\n",
      "score low: 1.2811258511370922\n",
      "- R2 METRICS FOR DIS:\n",
      "r2 close: 0.9961304576647064\n",
      "r2 high: 0.9976096843840434\n",
      "r2 low: 0.997621736723708\n",
      "67 METRICS FOR MS:\n",
      "score close: 1.3349015433146771\n",
      "score high: 1.069826092968983\n",
      "score low: 1.3216576871144246\n",
      "- R2 METRICS FOR MS:\n",
      "r2 close: 0.9933278099597304\n",
      "r2 high: 0.9957397595640061\n",
      "r2 low: 0.9944226272469374\n",
      "68 METRICS FOR CRM:\n",
      "score close: 6.644290393397116\n",
      "score high: 4.139005152069581\n",
      "score low: 2.3760693281680556\n",
      "- R2 METRICS FOR CRM:\n",
      "r2 close: 0.990084267416544\n",
      "r2 high: 0.994707586675387\n",
      "r2 low: 0.9974456041099287\n",
      "69 METRICS FOR PFE:\n",
      "score close: 0.9822150789590246\n",
      "score high: 0.48919083545485653\n",
      "score low: 0.5085147459344213\n",
      "- R2 METRICS FOR PFE:\n",
      "r2 close: 0.9855535845122291\n",
      "r2 high: 0.9947030547607185\n",
      "r2 low: 0.9949285540337397\n",
      "70 METRICS FOR UNP:\n",
      "score close: 3.407026576804349\n",
      "score high: 1.5963110393309687\n",
      "score low: 2.5898986148068226\n",
      "- R2 METRICS FOR UNP:\n",
      "r2 close: 0.9960547354013911\n",
      "r2 high: 0.9986265600169894\n",
      "r2 low: 0.9978375205350436\n",
      "71 METRICS FOR COST:\n",
      "score close: 3.3732095664763553\n",
      "score high: 2.5728484372058547\n",
      "score low: 4.949107262025397\n",
      "- R2 METRICS FOR COST:\n",
      "r2 close: 0.9986532486752211\n",
      "r2 high: 0.9989139250341159\n",
      "r2 low: 0.9984750858521131\n",
      "72 METRICS FOR INTU:\n",
      "score close: 9.6748873639777\n",
      "score high: 3.5986465281750775\n",
      "score low: 4.1313440407136355\n",
      "- R2 METRICS FOR INTU:\n",
      "r2 close: 0.9950621726226141\n",
      "r2 high: 0.9983246820071392\n",
      "r2 low: 0.9984459496334553\n",
      "73 METRICS FOR MA:\n",
      "score close: 8.448982583651238\n",
      "score high: 3.825435971788874\n",
      "score low: 4.941629332986248\n",
      "- R2 METRICS FOR MA:\n",
      "r2 close: 0.9932103207245848\n",
      "r2 high: 0.9971433054436563\n",
      "r2 low: 0.9978278577235985\n",
      "74 METRICS FOR BLK:\n",
      "score close: 19.068147453246826\n",
      "score high: 9.09838152199864\n",
      "score low: 6.8387779159239495\n",
      "- R2 METRICS FOR BLK:\n",
      "r2 close: 0.9899266882185552\n",
      "r2 high: 0.9959488312976631\n",
      "r2 low: 0.9975959540769491\n",
      "75 METRICS FOR REGN:\n",
      "score close: 18.874143894368093\n",
      "score high: 6.752473279570478\n",
      "score low: 8.532914545401988\n",
      "- R2 METRICS FOR REGN:\n",
      "r2 close: 0.9913277882069857\n",
      "r2 high: 0.9982782223976271\n",
      "r2 low: 0.9978547787493502\n",
      "76 METRICS FOR ADI:\n",
      "score close: 2.5052088902178538\n",
      "score high: 1.5749729405445267\n",
      "score low: 1.2422479819102459\n",
      "- R2 METRICS FOR ADI:\n",
      "r2 close: 0.9953710955248536\n",
      "r2 high: 0.9973146344411339\n",
      "r2 low: 0.9983335893729787\n",
      "77 METRICS FOR AMD:\n",
      "score close: 1.718984342515319\n",
      "score high: 1.3781182045618214\n",
      "score low: 1.2538809206351698\n",
      "- R2 METRICS FOR AMD:\n",
      "r2 close: 0.9946090360936876\n",
      "r2 high: 0.9962816680504546\n",
      "r2 low: 0.9966272915497434\n",
      "78 METRICS FOR TXN:\n",
      "score close: 3.2663795229900314\n",
      "score high: 1.8451000211708037\n",
      "score low: 1.269840287396228\n",
      "- R2 METRICS FOR TXN:\n",
      "r2 close: 0.9945135349876696\n",
      "r2 high: 0.9971850992353558\n",
      "r2 low: 0.9985257854279884\n",
      "79 METRICS FOR COP:\n",
      "score close: 1.4684962399034616\n",
      "score high: 2.0691937392973996\n",
      "score low: 1.6064517143739754\n",
      "- R2 METRICS FOR COP:\n",
      "r2 close: 0.9895457685280881\n",
      "r2 high: 0.9856578798467498\n",
      "r2 low: 0.9900128008474072\n",
      "80 METRICS FOR PGR:\n",
      "score close: 3.033839691882153\n",
      "score high: 2.2247336113788037\n",
      "score low: 1.011139549691993\n",
      "- R2 METRICS FOR PGR:\n",
      "r2 close: 0.9909650487066949\n",
      "r2 high: 0.9949612878256155\n",
      "r2 low: 0.9981797079657043\n",
      "81 METRICS FOR ADP:\n",
      "score close: 2.044482223480102\n",
      "score high: 1.4328782292254958\n",
      "score low: 1.9995582140114412\n",
      "- R2 METRICS FOR ADP:\n",
      "r2 close: 0.9978044688097613\n",
      "r2 high: 0.9986983107957217\n",
      "r2 low: 0.9982241556755077\n",
      "82 METRICS FOR BX:\n",
      "score close: 2.8361310299974827\n",
      "score high: 1.6123118421472362\n",
      "score low: 1.0725674963009046\n",
      "- R2 METRICS FOR BX:\n",
      "r2 close: 0.988690568005907\n",
      "r2 high: 0.9939464824857106\n",
      "r2 low: 0.996534274254129\n",
      "83 METRICS FOR CVS:\n",
      "score close: 1.661866219072457\n",
      "score high: 1.1085906783260973\n",
      "score low: 0.8816002286581629\n",
      "- R2 METRICS FOR CVS:\n",
      "r2 close: 0.9932382223053465\n",
      "r2 high: 0.9960581282435198\n",
      "r2 low: 0.997249548082166\n",
      "84 METRICS FOR AMGN:\n",
      "score close: 5.679119280160192\n",
      "score high: 3.2290128715545774\n",
      "score low: 2.0069165340867867\n",
      "- R2 METRICS FOR AMGN:\n",
      "r2 close: 0.990940216937892\n",
      "r2 high: 0.9967376102595129\n",
      "r2 low: 0.9982936441088426\n",
      "85 METRICS FOR RTX:\n",
      "score close: 1.5525699186516575\n",
      "score high: 1.0801664291136714\n",
      "score low: 1.139983114755776\n",
      "- R2 METRICS FOR RTX:\n",
      "r2 close: 0.9890264090563291\n",
      "r2 high: 0.9942658789561464\n",
      "r2 low: 0.992742766393622\n",
      "86 METRICS FOR KO:\n",
      "score close: 0.8401487086192669\n",
      "score high: 0.5718141762607071\n",
      "score low: 0.5325434692413452\n",
      "- R2 METRICS FOR KO:\n",
      "r2 close: 0.9920582679081209\n",
      "r2 high: 0.9962297059115739\n",
      "r2 low: 0.9960486455013847\n",
      "87 METRICS FOR UBER:\n",
      "score close: 2.4262566925376974\n",
      "score high: 1.9402163071444385\n",
      "score low: 2.464035712689909\n",
      "- R2 METRICS FOR UBER:\n",
      "r2 close: 0.9109159481102859\n",
      "r2 high: 0.9405400969194537\n",
      "r2 low: 0.910782498895421\n",
      "88 METRICS FOR JPM:\n",
      "score close: 3.7102429640819747\n",
      "score high: 1.504742158560389\n",
      "score low: 1.3766965331801448\n",
      "- R2 METRICS FOR JPM:\n",
      "r2 close: 0.9865830316971406\n",
      "r2 high: 0.9963179085425672\n",
      "r2 low: 0.9970027911025668\n",
      "89 METRICS FOR GS:\n",
      "score close: 9.001516854619405\n",
      "score high: 4.965140850572701\n",
      "score low: 6.033820759723464\n",
      "- R2 METRICS FOR GS:\n",
      "r2 close: 0.9812065557009756\n",
      "r2 high: 0.9927883204802905\n",
      "r2 low: 0.9911117553766221\n",
      "90 METRICS FOR ^NDX:\n",
      "score close: 247.69486101142851\n",
      "score high: 135.76662359888775\n",
      "score low: 85.95866898992455\n",
      "- R2 METRICS FOR ^NDX:\n",
      "r2 close: 0.9956342803364974\n",
      "r2 high: 0.9971111900627575\n",
      "r2 low: 0.9987484620824177\n",
      "91 METRICS FOR ABBV:\n",
      "score close: 1.716620002311018\n",
      "score high: 1.6450407361896437\n",
      "score low: 2.001454782222516\n",
      "- R2 METRICS FOR ABBV:\n",
      "r2 close: 0.9949616570859333\n",
      "r2 high: 0.9957538736571582\n",
      "r2 low: 0.993442982231391\n",
      "92 METRICS FOR PEP:\n",
      "score close: 2.9015314010252435\n",
      "score high: 1.257937553896004\n",
      "score low: 0.9870893654574352\n",
      "- R2 METRICS FOR PEP:\n",
      "r2 close: 0.992216546867746\n",
      "r2 high: 0.9972767913261399\n",
      "r2 low: 0.9981055587675528\n",
      "93 METRICS FOR ACN:\n",
      "score close: 2.2565116338461757\n",
      "score high: 1.844238105835206\n",
      "score low: 2.59845599055769\n",
      "- R2 METRICS FOR ACN:\n",
      "r2 close: 0.9986169371297718\n",
      "r2 high: 0.998503960359377\n",
      "r2 low: 0.998597200307317\n",
      "94 METRICS FOR NEE:\n",
      "score close: 0.586691126765975\n",
      "score high: 0.5817333006954576\n",
      "score low: 0.9609275927026588\n",
      "- R2 METRICS FOR NEE:\n",
      "r2 close: 0.9977482975485624\n",
      "r2 high: 0.9981999138770745\n",
      "r2 low: 0.997432869137171\n",
      "95 METRICS FOR INTC:\n",
      "score close: 0.8935667771412187\n",
      "score high: 0.6914895168748726\n",
      "score low: 0.6562177926182268\n",
      "- R2 METRICS FOR INTC:\n",
      "r2 close: 0.9905986914015197\n",
      "r2 high: 0.9937209067227841\n",
      "r2 low: 0.993885146746739\n",
      "96 METRICS FOR LIN:\n",
      "score close: 4.090747962706539\n",
      "score high: 2.497027531972372\n",
      "score low: 2.5044462135039183\n",
      "- R2 METRICS FOR LIN:\n",
      "r2 close: 0.9971172578994939\n",
      "r2 high: 0.9983620535998192\n",
      "r2 low: 0.9984035001098249\n",
      "97 METRICS FOR BAC:\n",
      "score close: 1.696669023103982\n",
      "score high: 0.8519822215938185\n",
      "score low: 0.7062507967872312\n",
      "- R2 METRICS FOR BAC:\n",
      "r2 close: 0.976154893419509\n",
      "r2 high: 0.9917984297354729\n",
      "r2 low: 0.9942803475441583\n",
      "98 METRICS FOR WFC:\n",
      "score close: 1.7784886967226206\n",
      "score high: 0.8927355002207928\n",
      "score low: 0.7724687978445766\n",
      "- R2 METRICS FOR WFC:\n",
      "r2 close: 0.9631677519359458\n",
      "r2 high: 0.9876141968325989\n",
      "r2 low: 0.9902829950606082\n",
      "99 METRICS FOR NFLX:\n",
      "score close: 5.555429891074155\n",
      "score high: 8.657277041697597\n",
      "score low: 13.509635445296047\n",
      "- R2 METRICS FOR NFLX:\n",
      "r2 close: 0.9962799979828721\n",
      "r2 high: 0.9961177402437816\n",
      "r2 low: 0.9919002830581067\n",
      "100 METRICS FOR ADBE:\n",
      "score close: 5.14677286071471\n",
      "score high: 3.488932213534313\n",
      "score low: 5.237209365071063\n",
      "- R2 METRICS FOR ADBE:\n",
      "r2 close: 0.997665531710131\n",
      "r2 high: 0.9985184947558219\n",
      "r2 low: 0.9979817168872159\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for symbol in df_data:\n",
    "    count += 1\n",
    "    \n",
    "    df_data[symbol].reset_index(inplace=True)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error\n",
    "\n",
    "    score_c = mean_absolute_error(df_data[symbol][['close']].iloc[seq_length:], df_pred[symbol]['pred_c'])\n",
    "    r2_c = r2_score(df_data[symbol][['close']].iloc[seq_length:], df_pred[symbol]['pred_c'])\n",
    "    df_data[symbol]['mae_c'] = score_c\n",
    "    \n",
    "    score_h = mean_absolute_error(df_data[symbol][['high']].iloc[seq_length:], df_pred[symbol]['pred_h'])\n",
    "    r2_h = r2_score(df_data[symbol][['high']].iloc[seq_length:], df_pred[symbol]['pred_h'])\n",
    "    df_data[symbol]['mae_h'] = score_h\n",
    "    \n",
    "    score_l = mean_absolute_error(df_data[symbol][['low']].iloc[seq_length:], df_pred[symbol]['pred_l'])\n",
    "    r2_l = r2_score(df_data[symbol][['low']].iloc[seq_length:], df_pred[symbol]['pred_l'])\n",
    "    df_data[symbol]['mae_l'] = score_l\n",
    "    \n",
    "    print(f'{count} METRICS FOR {symbol}:')\n",
    "    print(f'score close: {score_c}')\n",
    "    print(f'score high: {score_h}')\n",
    "    print(f'score low: {score_l}')\n",
    "\n",
    "    print(f'- R2 METRICS FOR {symbol}:')\n",
    "    print(f'r2 close: {r2_c}')\n",
    "    print(f'r2 high: {r2_h}')\n",
    "    print(f'r2 low: {r2_l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1897fff-1db7-4f82-b3ad-9ae23524d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done for VRTX\n",
      "2 done for MDLZ\n",
      "3 done for TMO\n",
      "4 done for UNH\n",
      "5 done for TJX\n",
      "6 done for AAPL\n",
      "7 done for BKNG\n",
      "8 done for V\n",
      "9 done for LOW\n",
      "10 done for PM\n",
      "11 done for CMCSA\n",
      "12 done for HD\n",
      "13 done for GOOG\n",
      "14 done for AXP\n",
      "15 done for NVDA\n",
      "16 done for SBUX\n",
      "17 done for PG\n",
      "18 done for SPGI\n",
      "19 done for AMZN\n",
      "20 done for ORCL\n",
      "21 done for NKE\n",
      "22 done for CVX\n",
      "23 done for SYK\n",
      "24 done for TMUS\n",
      "25 done for XOM\n",
      "26 done for LRCX\n",
      "27 done for AMAT\n",
      "28 done for HON\n",
      "29 done for ABNB\n",
      "30 done for GE\n",
      "31 done for TSLA\n",
      "32 done for MRK\n",
      "33 done for BSX\n",
      "34 done for UPS\n",
      "35 done for LLY\n",
      "36 done for VZ\n",
      "37 done for T\n",
      "38 done for MSFT\n",
      "39 done for CI\n",
      "40 done for ETN\n",
      "41 done for JNJ\n",
      "42 done for PANW\n",
      "43 done for MDT\n",
      "44 done for DE\n",
      "45 done for AVGO\n",
      "46 done for ELV\n",
      "47 done for SHOP\n",
      "48 done for DHR\n",
      "49 done for BA\n",
      "50 done for C\n",
      "51 done for META\n",
      "52 done for SCHW\n",
      "53 done for CB\n",
      "54 done for MCD\n",
      "55 done for LMT\n",
      "56 done for BMY\n",
      "57 done for QCOM\n",
      "58 done for ABT\n",
      "59 done for NOW\n",
      "60 done for IBM\n",
      "61 done for ISRG\n",
      "62 done for CAT\n",
      "63 done for WMT\n",
      "64 done for CSCO\n",
      "65 done for MMC\n",
      "66 done for DIS\n",
      "67 done for MS\n",
      "68 done for CRM\n",
      "69 done for PFE\n",
      "70 done for UNP\n",
      "71 done for COST\n",
      "72 done for INTU\n",
      "73 done for MA\n",
      "74 done for BLK\n",
      "75 done for REGN\n",
      "76 done for ADI\n",
      "77 done for AMD\n",
      "78 done for TXN\n",
      "79 done for COP\n",
      "80 done for PGR\n",
      "81 done for ADP\n",
      "82 done for BX\n",
      "83 done for CVS\n",
      "84 done for AMGN\n",
      "85 done for RTX\n",
      "86 done for KO\n",
      "87 done for UBER\n",
      "88 done for JPM\n",
      "89 done for GS\n",
      "90 done for ^NDX\n",
      "91 done for ABBV\n",
      "92 done for PEP\n",
      "93 done for ACN\n",
      "94 done for NEE\n",
      "95 done for INTC\n",
      "96 done for LIN\n",
      "97 done for BAC\n",
      "98 done for WFC\n",
      "99 done for NFLX\n",
      "100 done for ADBE\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "remaining_columns = ('date','open','high','low','close','volume','rsi_14','ma_9','mae_c','mae_h','mae_l')\n",
    "\n",
    "for symbol in df_data:\n",
    "    count += 1\n",
    "\n",
    "    df_data[symbol] = df_data[symbol][list(remaining_columns)]\n",
    "\n",
    "    df_data[symbol]['mpe_c'] = (df_data[symbol]['mae_c'].iloc[-1] / df_data[symbol]['close'].iloc[-1]) * 100\n",
    "    df_data[symbol]['mpe_h'] = (df_data[symbol]['mae_h'].iloc[-1] / df_data[symbol]['high'].iloc[-1]) * 100\n",
    "    df_data[symbol]['mpe_l'] = (df_data[symbol]['mae_l'].iloc[-1] / df_data[symbol]['low'].iloc[-1]) * 100\n",
    "    \n",
    "    y_pred_c_series = pd.Series(df_pred[symbol]['pred_c'].reshape(1,-1)[0])\n",
    "    y_pred_h_series = pd.Series(df_pred[symbol]['pred_h'].reshape(1,-1)[0])\n",
    "    y_pred_l_series = pd.Series(df_pred[symbol]['pred_l'].reshape(1,-1)[0])\n",
    "    df_data[symbol]['pred_close'] = y_pred_c_series\n",
    "    df_data[symbol]['pred_highs'] = y_pred_h_series\n",
    "    df_data[symbol]['pred_lows'] = y_pred_l_series\n",
    "    df_data[symbol]['pred_close'] = df_data[symbol]['pred_close'].shift(seq_length)\n",
    "    df_data[symbol]['pred_highs'] = df_data[symbol]['pred_highs'].shift(seq_length)\n",
    "    df_data[symbol]['pred_lows'] = df_data[symbol]['pred_lows'].shift(seq_length)\n",
    "    df_data[symbol].to_excel(f'data_w_pred/{symbol}_w_pred.xlsx')\n",
    "\n",
    "    print(f'{count} done for {symbol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c02967a-2300-4ef1-b2e3-d8e6fd865de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'rsi_14', 'ma_9',\n",
       "       'mae_c', 'mae_h', 'mae_l', 'mpe_c', 'mpe_h', 'mpe_l', 'pred_close',\n",
       "       'pred_highs', 'pred_lows'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['AAPL'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388bac8-f34c-4e8b-9198-fe645ea3cad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9d7dd-c6e1-4b67-86bd-84dfe3e51d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
